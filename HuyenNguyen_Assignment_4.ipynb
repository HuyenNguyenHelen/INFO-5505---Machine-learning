{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " HuyenNguyen_Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKk4NLIEtq1P6XOw+KH0ro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/INFO-5505---Machine-learning/blob/main/HuyenNguyen_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_yMppN_P_GC"
      },
      "source": [
        "# Assignment 4: Random Forest\r\n",
        "* Dataset: [Breast Cancer Wisconsin](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)\r\n",
        "* Goals: Given the Breast Cancer Features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass, train a model for predicting/diagnosing whether the observations are maglinant (M) or benign (B)\r\n",
        "*   Dependent variable/ Target variable: **diagnosis**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v4G3WymSZFw"
      },
      "source": [
        "# Importing essential libraries \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suY0adZlSPJc"
      },
      "source": [
        "## Loading the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "THqvxiSxTIiR",
        "outputId": "215b91ee-0892-4969-c4fa-0ea185d20463"
      },
      "source": [
        "# Loading the dataset\r\n",
        "data=pd.read_csv('/content/data-breastCancer.csv')\r\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6jwB19pjKH7"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA5PxtKNYmnP",
        "outputId": "93926c17-5c4c-46df-c517-c219d31be119"
      },
      "source": [
        "# Printing column names\r\n",
        "print('the number of columns: {}'.format(len(data.columns)))\r\n",
        "print('column names: \\n', [name for name in data.columns])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of columns: 33\n",
            "column names: \n",
            " ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mPgocuAY1dQ"
      },
      "source": [
        "There are 33 variables including the independent and dependent variables. However, two of them contain no useful information: 'id' and 'Unnamed: 32'. Therefore, we will delete these columns in the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "3vkeJ2Xabk_k",
        "outputId": "d2da6c49-8a2c-4cfa-ea0f-8324f4cf425b"
      },
      "source": [
        "# Explore the dataset with some summary statistics\r\n",
        "data.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "count  5.690000e+02   569.000000  ...               569.000000          0.0\n",
              "mean   3.037183e+07    14.127292  ...                 0.083946          NaN\n",
              "std    1.250206e+08     3.524049  ...                 0.018061          NaN\n",
              "min    8.670000e+03     6.981000  ...                 0.055040          NaN\n",
              "25%    8.692180e+05    11.700000  ...                 0.071460          NaN\n",
              "50%    9.060240e+05    13.370000  ...                 0.080040          NaN\n",
              "75%    8.813129e+06    15.780000  ...                 0.092080          NaN\n",
              "max    9.113205e+08    28.110000  ...                 0.207500          NaN\n",
              "\n",
              "[8 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs-w788QdFae"
      },
      "source": [
        "The min, max, mean, and standard deviation from the above summary statistics of the dataset indicate that our data have different scales or ranges. However, fortunately, decision tree or random forest algorithms can handle well this issue because they made local optimums, unlike logistic regression or others. Therefore, we do not have to normalize our data, for maintaining the model's interpretability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgKSAJIOS7jq"
      },
      "source": [
        "### Exploring missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOE7WAcvajZp",
        "outputId": "5b452807-e083-457d-8816-9ef27e03399a"
      },
      "source": [
        "# Checking missing values in the dataset\r\n",
        "data.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           0\n",
              "diagnosis                    0\n",
              "radius_mean                  0\n",
              "texture_mean                 0\n",
              "perimeter_mean               0\n",
              "area_mean                    0\n",
              "smoothness_mean              0\n",
              "compactness_mean             0\n",
              "concavity_mean               0\n",
              "concave points_mean          0\n",
              "symmetry_mean                0\n",
              "fractal_dimension_mean       0\n",
              "radius_se                    0\n",
              "texture_se                   0\n",
              "perimeter_se                 0\n",
              "area_se                      0\n",
              "smoothness_se                0\n",
              "compactness_se               0\n",
              "concavity_se                 0\n",
              "concave points_se            0\n",
              "symmetry_se                  0\n",
              "fractal_dimension_se         0\n",
              "radius_worst                 0\n",
              "texture_worst                0\n",
              "perimeter_worst              0\n",
              "area_worst                   0\n",
              "smoothness_worst             0\n",
              "compactness_worst            0\n",
              "concavity_worst              0\n",
              "concave points_worst         0\n",
              "symmetry_worst               0\n",
              "fractal_dimension_worst      0\n",
              "Unnamed: 32                569\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULJ7Z-qMd8Gm"
      },
      "source": [
        "As we can see, there is no missing values, so we do not need to do data cleaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uok_QjEnTXgB"
      },
      "source": [
        "### Exploring the data distribution of the dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9J2RI7ojU-L",
        "outputId": "c6c15a7e-b9ad-4cd7-ce99-2056af2b163e"
      },
      "source": [
        "# Explore data distribution on the dependent variable \r\n",
        "print( 'class distribution in the dependent variable: \\n', data['diagnosis'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class distribution in the dependent variable: \n",
            " B    357\n",
            "M    212\n",
            "Name: diagnosis, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "QCNEvWoPZsJX",
        "outputId": "921e9a4f-cf8a-4c17-dc80-0e0c02c43744"
      },
      "source": [
        "sns.countplot(x='diagnosis', data=data)\r\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DflcvXI8Uq_q"
      },
      "source": [
        "The dependent variable \"diagnosis\" contains binary values: M (malignant) and B (benight). The proportion of the two classes are imbalanced as shown from the above bar chart. Although the imbalance is not much, we should keep this in mind when we train and validate the model later, ensuring our models have aquadetely learned and tested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dGEXSmxdN5-"
      },
      "source": [
        "### Preprocessing\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW1oVTNisMQb"
      },
      "source": [
        "* Deleting the columns contain no information: \"id\" and \"Unnamed: 32\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyYMcu6vb1CS",
        "outputId": "809b437f-74d1-4fc8-d0db-9fe173c5141c"
      },
      "source": [
        "# Deleting the columns contain no information\r\n",
        "del data['id']\r\n",
        "del data ['Unnamed: 32']\r\n",
        "\r\n",
        "# Printing the numer of columns after deleting id columns\r\n",
        "print('the number of columns: ', len(data.columns))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of columns:  31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeA6b9_RsF0k"
      },
      "source": [
        "* Convert discrete data into numeric. Here, only the dependent variable contain discrete values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "18EzjauFdlHA",
        "outputId": "54dc3e8d-5d2d-4523-fe0f-ad19961f6f42"
      },
      "source": [
        "data['diagnosis']=np.where(data['diagnosis']=='M', 1, 0)\r\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0          1        17.99  ...          0.4601                  0.11890\n",
              "1          1        20.57  ...          0.2750                  0.08902\n",
              "2          1        19.69  ...          0.3613                  0.08758\n",
              "3          1        11.42  ...          0.6638                  0.17300\n",
              "4          1        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQknD5EzdDs1"
      },
      "source": [
        "## Developing Random Forest models\r\n",
        "Random forest algorithm overcomes limitations of Decision tree that is sensitive to any minor changes in the input data and tend to overfit because it maximize local optimum, performing poorly in unseen data. Random forest also solves problems of Bagging (Boostrapping Aggregation) Decision tree that uses all features for spliting creation, creating complexity of the tree.\r\n",
        "Random forest not only  generates samples with bootstrapping method like Bagging, but also take random collection of features for each subset.\r\n",
        "\r\n",
        "Here we will create a base model with Random Forest in sklearn. Then we will experiment a variety of parameters to select the best parameters for tuning the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxpCOnxQi9Av"
      },
      "source": [
        "### Spliting the data into training and testing sets\r\n",
        "Here we will split the data into two parts: training set (80%), and test set (20%). \r\n",
        "\r\n",
        "For the training set (80%), we will then use k-fold cross validation method for validating our models. By doing so, the training set will be splitted into k-folds (i.e., we decide to divide into 10 folds). For each iteration, 9 folds will be used for training and 1 set for validating . \r\n",
        "\r\n",
        "We will not use the test set (20%) until we have finished training, and model selection. We only use the test set for evaluating our selected model to ensure having the most reliable model evaluation result before deploying the model.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY81vgPTi5gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4cc9ff-2146-4e80-fe44-c5a737ead1f9"
      },
      "source": [
        "# Spliting the data into training (80%) and testing (20%) sets\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X = data.drop('diagnosis', axis=1)\r\n",
        "y = data['diagnosis']\r\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y,train_size = 0.8)\r\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\r\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes of X_train, y_train:  (455, 30) (455,)\n",
            "Shapes of X_test, y_test:  (114, 30) (114,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK488A8ORL5z"
      },
      "source": [
        "### Based Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgo9TUt3dAyS"
      },
      "source": [
        "# Building a Random forest model\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "base_rf = RandomForestClassifier (random_state = 42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGr1wDBTtOWe",
        "outputId": "ede8476b-41a1-488a-e92e-22d9683a44df"
      },
      "source": [
        "# Validate the model's performance using k-fold cross validation\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "cv = cross_validate (base_rf, X_train, y_train, cv = 10)\r\n",
        "print(\"Base model's accuracy score of 10-fold cross validation:\\n\", cv['test_score'])\r\n",
        "print(\"Base model's cross validation accuracy mean score: \\n\", cv['test_score'].mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model's accuracy score of 10-fold cross validation:\n",
            " [0.95652174 0.95652174 0.89130435 0.97826087 0.97826087 1.\n",
            " 0.95555556 0.91111111 0.97777778 0.97777778]\n",
            "Base model's cross validation accuracy score: \n",
            " 0.9583091787439614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYqtnuqZSg4J"
      },
      "source": [
        "The k-fold validation allows us to get a generalized estimate performance score of the model. The base model performed quite well, with an accuracy score of 0.958 on the training set. However, we still hope to improve the performance by tuning the hyperparameters. \r\n",
        "\r\n",
        "Let's see parameters used by the base model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wHy2MSwFF7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1e028e-b51d-4cf1-f294-87a9f989fe54"
      },
      "source": [
        "# Checking current parameters of the base model\r\n",
        "print(\"Base model's parameters:\\n\", base_rf.get_params())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model's parameters:\n",
            " {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPtJVhkde_wG"
      },
      "source": [
        "### Tunning parameters\r\n",
        "We can use RandomizedSearchCV or GridSearchCV with Cross Validation for searching the best parameters. However, RandomizedSearchCV is more suitable when we have not determined any certain parameters, except for boostrapping. \r\n",
        "\r\n",
        "Below are parameters that are most important for us to tune:\r\n",
        "\r\n",
        "\r\n",
        "*   'bootstrap': randomly sampling with replacement. We expect to use this method to generate resample of the training data for building trees\r\n",
        "*   'max_depth': the maximum depth of the tree. It is true that increasing max_depth can improve accuracy of the model on the training set, but the model perform poorly in the unseen data. To avoid the overfitting problem of the Decision Tree that is a fully-grown tree, we should limit this parameter.\r\n",
        "*   'max_features': for setting the number of features to consider when looking for the best split\r\n",
        "*   'min_sample_leaf': The minimum number of samples required to be at a leaf node. We will not want one or two sample at each leaf node.\r\n",
        "*   'min_samples_split':The minimum number of samples required to split an internal node\r\n",
        "*   'n_estimators': The number of trees in the forest. Note that it is not true that more trees the model has, the better the model performs.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gWCzalNGLSy"
      },
      "source": [
        "#### Searching the best parameters for tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkxDrfIde3hB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23c9a96-0f4a-4a4e-962a-07dbad8a3717"
      },
      "source": [
        "# Tunning parameters\r\n",
        "\r\n",
        "# Using randomized search on hyperparameters\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "\r\n",
        "# Setting a grid of parameters to sample \r\n",
        "# Setting the number of trees in random forest classifiers\r\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10, endpoint = True)]\r\n",
        "# Setting the number of features for each tree\r\n",
        "max_features = ['auto', 'sqrt', 'log2']\r\n",
        "# Setting the number of depth levels for each tree\r\n",
        "max_depth = [int(x) for x in np.linspace(start = 3, stop = 36, num=33, endpoint = True)]\r\n",
        "# Setting the minimum number of samples required to split an internal node\r\n",
        "min_samples_split = [5, 10, 15]\r\n",
        "# Setting the minimum number of samples required to be at a leaf node \r\n",
        "min_samples_leaf = [3, 4,5]\r\n",
        "# Select bootstrap method for building trees \r\n",
        "bootstrap = ['True']\r\n",
        "\r\n",
        "# Create the random grid\r\n",
        "random_grid = {'n_estimators':n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\r\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36], 'min_samples_split': [5, 10, 15], 'min_samples_leaf': [3, 4, 5], 'bootstrap': ['True']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o57zWmwiCdP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d1e0df-bec9-49d3-a6d6-e960c248b34f"
      },
      "source": [
        "# Create a base randomforest model for tuning\r\n",
        "tune_base_rf = RandomForestClassifier(random_state=42)\r\n",
        "\r\n",
        "# Create a randomized search cross validation model for searching for the best hyperparameters for the base rf model over 100 parameters combination\r\n",
        "random_search_rf = RandomizedSearchCV (estimator=tune_base_rf, param_distributions  = random_grid, random_state=42, cv = 10, n_iter=100)\r\n",
        "\r\n",
        "# fit the randomized search CV model into the training set\r\n",
        "random_search_rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Print the best parameters\r\n",
        "random_search_rf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': 'True',\n",
              " 'max_depth': 19,\n",
              " 'max_features': 'log2',\n",
              " 'min_samples_leaf': 5,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 600}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjO3BL-S1PZ"
      },
      "source": [
        "Using the cross validation randomized search method, we found the best parameters for our tuned random forest model. Hopefully, we could achieve a bit higher performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vjgI50oGC9i"
      },
      "source": [
        "### The tuned random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3HHL26EGfXT",
        "outputId": "9b4cfa86-5f8b-48a9-a4cd-ac8a0737de68"
      },
      "source": [
        "# Creating a tuned random forest model with the best parameters choosen by  the cv randomized search algorithm\r\n",
        "tuned_rf = RandomForestClassifier (n_estimators = 600, min_samples_split = 10, min_samples_leaf = 5, max_features = 'log2',  max_depth = 19, bootstrap = True, random_state=42)\r\n",
        "\r\n",
        "# Validating the model using k-fold cross validation (k=10)\r\n",
        "tuned_cv = cross_validate (tuned_rf, X_train, y_train, cv = 10)\r\n",
        "print(\"The tuned model's accuracy scores in 5-fold cross validation:\\n\", tuned_cv['test_score'])\r\n",
        "print(\"The final base tuned model's cv accuracy score: \\n\", tuned_cv['test_score'].mean())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tuned model's accuracy scores in 5-fold cross validation:\n",
            " [0.95604396 0.93406593 0.93406593 0.91208791 0.97802198]\n",
            "The final base tuned model's cv accuracy score: \n",
            " 0.9428571428571427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUdiWgz-Za8C"
      },
      "source": [
        "The tuned model performed a bit better than the base model did. Therefore, we will select it as our final model.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igaqaxhxr4kj"
      },
      "source": [
        "### Evaluating the selected model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri5aECaE20O6"
      },
      "source": [
        "#### With accuracy *score*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S9xtqlJWFBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e5b8b3-bb5a-4ac9-de5e-af43cf100600"
      },
      "source": [
        "# Fit the selected model to the training set\r\n",
        "tuned_rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Applying the selected model to make prediction on the test set\r\n",
        "pred = tuned_rf.predict(X_test)\r\n",
        "\r\n",
        "# Observing the estimate probability of classess in the test set\r\n",
        "pred_prob = tuned_rf.predict_proba (X_test)\r\n",
        "print ('class_0','\\t', 'class_1')\r\n",
        "print(pred_prob[:10])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_0 \t class_1\n",
            "[[1.68839031e-03 9.98311610e-01]\n",
            " [4.76190476e-04 9.99523810e-01]\n",
            " [9.98173942e-01 1.82605820e-03]\n",
            " [9.91854039e-01 8.14596052e-03]\n",
            " [9.85543952e-01 1.44560483e-02]\n",
            " [4.22249388e-03 9.95777506e-01]\n",
            " [1.01851852e-03 9.98981481e-01]\n",
            " [6.60525576e-01 3.39474424e-01]\n",
            " [6.02765877e-01 3.97234123e-01]\n",
            " [4.64293113e-01 5.35706887e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT8Pc2WW79ma"
      },
      "source": [
        "The result of the estimate probabilities show how classes were assigned. It is a nx2 array. The first column (dimension) is for class 0, and another for the class 1. In the first instance, it was assigned class 1 because it got a probability of 0.998 for this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psAItIyVj57U",
        "outputId": "65166673-8272-4e07-c236-b4459cbea961"
      },
      "source": [
        "# Evaluate the selected model on the test set with acurracy scores\r\n",
        "print('Accuracy of the selected model in the test set: {:.4f}'.format(tuned_rf.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the selected model in the test set: 0.9298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLjy1lDn3Fcb"
      },
      "source": [
        "#### With confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EescqEUnBCqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "d50a96f5-f10f-43c1-867a-28323430c8a7"
      },
      "source": [
        "# Evaluate the selected model on the test set  with confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "conf_matrix = confusion_matrix(y_test, pred )\r\n",
        "# visualizing confusion matrix\r\n",
        "sns.heatmap(conf_matrix, annot = True)\r\n",
        "plt.xlabel ('predicted values')\r\n",
        "plt.ylabel ('actual values')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'actual values')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpQfnpw917AJ"
      },
      "source": [
        "#### With the ROC curve\r\n",
        "We were aware of the imbalanced proportions of the two classes in previous section. Therefore, accuracy score may not make sense. Note that the Malignant (class 1) acounts a lower portion in the dataset. Even if True Positive is high, and False Negative is low, the cost of False Negative is quite high. Receiver Operating Characteristic (ROC) Curve is a good method that enables us to balance True Positive Rate (TPR) and False Positive Rate (FPR). \r\n",
        "\r\n",
        "*   TPR = TP/P = TP/(TP+FN)\r\n",
        "*   FPR = FP/N = FP/ (FP+TN)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvqaTtOrBpZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789918e9-55c2-44c4-fc9b-4b90291e97e4"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\r\n",
        "# Taking the probability of the class 1 (Malignant) on the test set\r\n",
        "pred_prob_c1 = pred_prob[:,1]\r\n",
        "\r\n",
        "# Getting True Positive Rate (tpr) and False Positive Rate (fpr)\r\n",
        "fpr, tpr, threshold = roc_curve (y_test,pred_prob_c1, pos_label = 1)\r\n",
        "\r\n",
        "# Computing Area Under the ROC Curve (roc_auc)\r\n",
        "roc_auc_score = roc_auc_score (y_test,pred_prob_c1)\r\n",
        "roc_auc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9825641025641025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uQeS22WmQp6U",
        "outputId": "45a8348a-9c90-416e-b747-e79bf1b8b2f3"
      },
      "source": [
        "# Visualizing the ROC Curve\r\n",
        "plt.plot( fpr, tpr)\r\n",
        "plt.plot([0,1], '--')\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.title (\"ROC Curve (AUC = {:.3f})\".format(roc_auc_score))\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU9fX/8dehSQcRRKUIKhbEvmLXVVCxm9jLLxrNlxh7SWIvIRo1GpPYRcWS2DUqVqyrRkFARJqiiAUQFIEFls7u+f3xuRvHYcssu3fuzsz7+XjMg3vv3Jl7PjvLnvncz73nY+6OiIgUriZJByAiIslSIhARKXBKBCIiBU6JQESkwCkRiIgUOCUCEZECp0QgUkdmdqCZPZd0HLnMzJ4xs4OSjkMCJQKplpl9bWbLzKzMzOaY2YNm1jZtn93N7C0zW2xmC83sBTPrm7ZPezP7h5l9G73Xl9F652qOa2Z2rplNMrMlZjbTzJ4ys23ibG8dXAfckLohinm6mU1J3zn6OQ5M23aqmf03Zb2FmV1jZl9Ebf7azIaZWa+GDNzMepnZ22a21Mw+S48rbd9uZva8mc2PPoMz0p7fz8zGmdmiqO2DU57b18wmmlmpmc0zs2fNrFvKy28Erm3ItsnaUyKQ2hzm7m2B7YEdgEsrnzCz3YDXgOeBjYDewCfA+2a2SbRPC+BNYGtgENAe2A2YB/Sv5pj/BM4DzgU6AZsDzwGH1DV4M2tW19fU8n47Ax3cfVTaU3sD6wObRPvU1dPA4cCJQAdgO+AjYEA9wq3KY8DHwHrA5cDTZtalmn3/DXwFdCX87P9iZvsCmFlz4Fngnije44BbzGy76LVTgAPdvSPhd+ML4K7KN3b30UB7Mytq2ObJWnF3PfSo8gF8DQxMWf8r8FLK+nvAnVW87hXg4Wj5N8D3QNsMj9kHKAf617BPCfCblPVTgf+mrDtwFuGPz1eEP0A3p73H88CF0fJGwDPA3Gj/c2s49lXAfVVsHwY8AvwHuL2mn2N6zMBAYBnQI+bPc3NgBdAu7TM8o4p920Y/xy4p24YC/4qWu0bPt055fgxwQhXvtQ5wPTAlbfu9wNVJ/57r4eoRSGbMrDtwEDAtWm8N7A48VcXuTwL7R8sDgVfdvSzDQw0AZnr4xlgfRwK7AH0J34KPMzMDMLN1gQOAx82sCfACoSfTLTr++WZ2YDXvuw0wNXVD9LM4mpAIHgGOj3pCmRoIjHb3GZm+wMxejE67VPV4sZqXbQ1Md/fFKds+ibavcYi0fyuX+wG4+/eEn+uvzaxp1DvcGEg93dXTzEoJSe73hC8SqT4l9HwkYUoEUpvnzGwxMAP4Abg62t6J8Pszu4rXzAYqz/+vV80+1anr/tW53t3nu/sywrdeB/aKnjsaGOnu3wE7E771DnH3le4+nfBN9fhq3rcjsDht2y8J37RfA14CmlO301h1brO7H+ruHat5HFrNy9oCC9O2LQTaVfH+i4H3gSvNrKWZ7QgcBbRO2e0xQg9pBeFnfHlqMnP3bz2cGuoMXAF8lnaYxYSfpyRMiUBqc6S7twOKgS356Q/8AqAC2LCK12wI/Bgtz6tmn+rUdf/qpP5BcuBx4IRo04mEb+4QvsVulPqNGriMcOqjKgtY8w/nKcCT7r7a3ZcTTjOdkvL8akJySNUcWBUtN1Sba1NGGKNJ1Z41E1ulkwjjPjMIp9f+DcwEMLMtCT/TXwEtCL2KP5rZGgnQ3ecDDwHPp43ZtANK17Yx0nCUCCQj7v4O8CBwc7S+BBgJHFPF7scSBogB3gAONLM2GR7qTaB7LYOIS/j5N9MNqgo5bf0x4Ggz25hwyuiZaPsM4Ku0b9Tt3P3gao49gXCuHfjfKbP9gJOjK6vmEHocB6dcFfUt0CvtfXoD30TLbwD9o/fKiJm9El2BVdXjlWpeNpkwmJ2ayLaLtq/B3b+Jeh5d3H0XwpeAylN2/YDP3X2Eu1e4+1RCb6i6S0KbEQbTUxPRVoRTU5K0pAcp9Gi8D9YcLO5C+CO8XbS+Z7R+LuHb3bqESwJLgT7RPusQBhFfJfQomhBOhVwGHFzNcW8jDPQWE75ttiScqrkkev46woBxa2CzaN/0weLNqnjfT4HXgWdTtjUFxgEXA62i9X7AztXEtiPhD2Dl+qXR+26Q9pgOnBPt81vCuMKWhPPsRcAcYFDK+wyPfk47Ef5otgPOAE5r4M90FCGZtwR+EX1WXarZd6sojhbAyYReXpfouU0JPYz9ojZtShg/Ghw9/0tgi+jz7kIYNxqX9v6fU8NFAXpk75F4AHo03kd6Ioi23QU8k7K+Z/RHuQxYRPhW2C/tNR2AfxC+fZcBXwK3AOtVc1wjXD46GVgKzAKeALaOnu9MOB9feR77mgwTwZXRc8ekbd+I0GOYQzj1Myq93Wn7jwF2iZY/q/yDn7bPH4Gx0XIT4BJCwlpEuLTy9LT9WwB/iv6YLiH0Fu4DejbwZ9or+ryWEZJTaqI/CZicsn4+4UqqJYRB4KK09zoWmBR9DjMJ9wY0iZ47h3AF1pLo5/o4sHHKa3dOTwx6JPew6EMRkQyZ2QHAme5+ZNKx5Cozewa4391fTjoWQYlARKTQabBYRKTAKRGIiBQ4JQIRkQLXoAW5sqFz587eq1evtXrtkiVLaNMm08vZ84PaXBjU5sJQnzZ/9NFHP7p7lQUGcy4R9OrVi7Fjx67Va0tKSiguLm7YgBo5tbkwqM2FoT5tNrNvqntOp4ZERAqcEoGISIFTIhARKXBKBCIiBU6JQESkwMWWCKKJt38ws0nVPG9mdquZTTOzCdHEFyIikmVx9ggeJExWXp2DCPPT9gEGkzKxtYiIZE9s9xG4+7tm1quGXY4gTHDuwCgz62hmG7p7Q0xTKI3Eox9+y/PjZ2X1mKWly7hr6sisHjNpanN+W6diOe0rSlnRpDVx3DqR5A1l3UiZTpBQz7wbVczdamaDCb0GunbtSklJyVodsKysbK1fm6uSbvNDHy7j28UV9GyXveGo8vJySksLawZEtTl/bVc+ifNXDWUJrflLxz/H8v85J+4sdvehwFCAoqIiX9s763QnYvbdNXUkHTvCE7/dLWvHTLrNSVCb89CyUnj9Shj3MHTaBA6/jVO+Xh1Lm5NMBLOAHinr3aNtIiKFraIc7j8A5n0Be5wHxZdC81bwdUksh0syEQwHzjazxwmTiS/U+ICIFLSl86HVutCkKQy4Etp3g27xX1AZWyIws8cIk493NrOZwNVAcwB3vxt4GTiYMEfrUuDXccWSqxpioDXpAbUpsxfRd8P2iR1fJCe4w4Qn4dWLYeA1sNOpsNVhWTt8nFcNnVDL8w6cFdfx88Hz42fl/B/Svhu254jtuyUdhkjjtXAmvHgBfPEadN8Zeuya9RByYrC4kPXdsH29BlrDgFr2BmpFpA4mPg0vnA9eDoNugP6Dw2mhLFMiEBFJSsuO0H0nOOyfsG6vxMJQIhARyZby1TDqDihfCXv/AfoMhM0GgFmiYSkRZFFdB39zfXxARFLMmQjPnw2zx8PWvwgDxGaJJwFQ9dGsqhz8zZQGWkXywOoV8Na1MLQYFs2CYx6Cox9oFAmgknoEWVbfwV8RyTHzvoT//gO2OQYO/Au07pR0RGtQIhARaWgrymDqy7DtsdC1L5w9Bjr1TjqqaikRiIg0pC/fghfOg9IZsOF20GWLRp0EQImgTup7p68Gf0Xy2LIF8NoV8PG/Yb3N4NcvhySQA5QI6qC+d/pq8FckT1WUw/0HwrxpsOeFsM/F0Lxl0lFlTImgjjTYKyL/s2ReSpG4q6BDd9ho+6SjqjNdPioiUlfuMP4xuG1HGPdQ2LbVoTmZBEA9AhGRuin9NtQH+vJN6LELbLxH0hHVmxKBiEimPnkCXrow9AgOugl2/g00yf0TK0oEIiKZarNe6AUc9g/o2DPpaBqMEoGISHXKV8EHt0HFatjnj7DZQNg0+SJxDU2JQESkKrM/CUXi5kyAfkc1qiJxDU2JQEQk1arl8M6N8P4/ofV6cOy/oO/hSUcVKyUCEZFU86eH00HbnQAHXhvuE8hzBZsI1qZchEpEiOSpFWXw2Yuw3fGhSNw5YxOdMSzbcv+6p7VU17kBQCUiRPLStDfgzl3h2TNg7tSwrYCSABRwjwBULkKkoC2dDyMug08eg86bw2mv5kyRuIZW0IlARApURTncf0AYD9jr92H+4BwqEtfQlAhEpHAs+RFadQpF4vb/E3ToARtum3RUiSuYRPDoh9/y0IfLuGvqSEADvyIFxR3GPxJOBQ28BopOgy0PSTqqRqNgEsHz42fx7eIKOnYM6xr4FSkQC74JM4ZNfxt67g699k46okanYBIBQM92TTQ4LFJIPnkcXrww3A18yN9gp9PyokhcQyuoRCAiBaZNF9h4dzj079CxR9LRNFpKBCKSP8pXwfv/gIoKKL4YNhsQHlIjJQIRyQ/fjQ9F4r6fCNsc81OROKmVEoGI5LZVy6DkhlAfqE1nOO6RMG2kZCzWURMzG2RmU81smpldUsXzPc3sbTP72MwmmNnBccYjInlowdcw8g7Y/kQ460MlgbUQW4/AzJoCdwD7AzOBMWY23N2npOx2BfCku99lZn2Bl4FeccUkInli+SI2mP0mUAzrbwXnjsurGcOyLc4eQX9gmrtPd/eVwOPAEWn7OFB5V1cH4LsY4xGRfPD5a3Dnbmwx9fafisQpCdRLnGME3YAZKeszgV3S9rkGeM3MzgHaAAOreiMzGwwMBujatSslJSV1Dqa0dBnl5eVr9dpcVlZWpjYXgEJoc/OVi9j0y/vZ4PsSlrTuwcdbXsXqybOB2UmHljVxfc5JDxafADzo7n8zs92Af5lZP3evSN3J3YcCQwGKioq8uLi4zge6a+pISktLWZvX5rKSkhK1uQDkfZsryuGO/mE8YJ+LabPXRaz+78j8bnMV4vqc40wEs4DUOzi6R9tSnQ4MAnD3kWbWEugM/BBjXCKSK8p+gNadQ5G4A64NReI26Jd0VHknzjGCMUAfM+ttZi2A44Hhaft8CwwAMLOtgJbA3BhjEpFc4A7jHobbiuCjB8K2LQ5SEohJbD0Cd19tZmcDI4CmwDB3n2xmQ4Cx7j4cuAi418wuIAwcn+ruHldMIpID5n8FL5wLX70LG+8JmxQnHVHei3WMwN1fJlwSmrrtqpTlKcAeccYgIjlk/KPw0kVgTUN9oB1PVZG4LEh6sFhE5CftNoDee8Mht0AHlYnPFiUCEUnO6pXw37+DV8C+l8Km+4WHZJUSgYgkY9ZHoUjcD1Ng2+NVJC5BSgQikl0rl8Lb18GoO6HtBnDC4+GKIEmMEoGIZFfpNzB6KOx4SphAvmWHpCMqeEoEIhK/5Qvh0xdgh5OjInEfQ4fuSUclESUCEYnX5yPghfOhbA507w9dNlcSaGR0ga6IxGPJj/DMb+DRY6FVRzj9jZAEpNFRj0BEGl5FOQw7EBZ8A8WXwZ4XQLMWSUcl1VAiEJGGs/h7aNMlKhJ3XZgnoGvfpKOSWmR8asjMWscZiIjksIoKGDsMbtsJPhoWtm0xSEkgR9SaCMxsdzObAnwWrW9nZnfGHpmI5IZ5X8LDh8OLF0C3HWDTAUlHJHWUyamhvwMHEpWQdvdPzGzvWKMSkdzw8b9DkbimLeCwW2HHX+nu4ByU0RiBu8+wn3+45fGEIyI5pUP30AM45GZov1HS0chayiQRzDCz3QE3s+bAecCn8YYlIo3S6hXw3i2hSNx+l4e5AjYpTjYmqbdMBovPAM4iTEY/C9geODPOoESkEZo5Fu7ZB965ARbODEXiJC9k0iPYwt1PSt1gZnsA78cTkog0KiuXwFtRkbj2G8GJT8LmByYdlTSgTHoEt2W4TUTyUekMGHMfFJ0GZ45SEshD1fYIzGw3YHegi5ldmPJUe8IcxCKSr5aVwpTnYadTYP0toyJxmjEsX9V0aqgF0Dbap13K9kXA0XEGJSIJ+uwlePFCWDIXeu4WFYlTEshn1SYCd38HeMfMHnT3b7IYk4gkoWwuvPJHmPwf6NoPTnhMReIKRCaDxUvN7CZga6Bl5UZ318SiIvmiohyGHRCuBtrvCtjjfGjaPOmoJEsySQSPAE8AhxIuJT0FmBtnUCKSJYtmQ9uuoUjcoBtDkbj1t0w6KsmyTK4aWs/d7wdWufs77n4aoN6ASC6rqAhXAt2+M4y9P2zb/AAlgQKVSY9gVfTvbDM7BPgO6BRfSCISqx+nwQvnwjfvh7uC++yfdESSsEwSwbVm1gG4iHD/QHvg/FijEpF4jHsYXv4DNFsHjrgDtj9JReKk9kTg7i9GiwuBfeF/dxaLSK7p2BM2GwiH/A3abZB0NNJI1HRDWVPgWEKNoVfdfZKZHQpcBrQCdshOiCKy1lavgHf+GpYHXKkicVKlmnoE9wM9gNHArWb2HVAEXOLuz2UjOBGph28/hOFnw4+fww4nhyJxOg0kVagpERQB27p7hZm1BOYAm7r7vOyEJiJrZUUZvPVn+PCeMF/Ayc+E00Ei1ajp8tGV7l4B4O7Lgel1TQJmNsjMpprZNDO7pJp9jjWzKWY22cwercv7i0gVFs6EsQ9A//+DM0cqCUitauoRbGlmE6JlAzaN1g1wd9+2pjeOxhjuAPYHZgJjzGy4u09J2acPcCmwh7svMLP169EWkYLVbFVZ+ONf9OtwL8B5n0D7DZMOS3JETYlgq3q+d39gmrtPBzCzx4EjgCkp+/wfcIe7LwBw9x/qeUyRwvPpC+w85hxYtQh67Qmd+ygJSJ3UVHSuvoXmugEzUtZnAruk7bM5gJm9TyhtfY27v5r+RmY2GBgM0LVrV0pKSuocTGnpMsrLy9fqtbmsrKxMbc5TLVYsYLNpQ1l/7gcsb7UxE7e5krJJswgTCea/QvmcU8XV5owmr49RM6APUAx0B941s23cvTR1J3cfCgwFKCoq8uLi4jof6K6pIyktLWVtXpvLSkpK1OZ8VFEOtxfBwlkw4CrGr9qOffYrrLGAgvic08TV5jgTwSzC5aeVurPmV5WZwIfuvgr4ysw+JySGMTHGJZK7Fs6CdhuGInEH/RU6bgxdNscL7JuxNKxMis5hZq3MbIs6vvcYoI+Z9TazFsDxwPC0fZ4j9AYws86EU0XT63gckfxXUREuB00tEtdnf80XIA2i1kRgZocB44FXo/XtzSz9D/oa3H01cDYwAvgUeNLdJ5vZEDM7PNptBDDPzKYAbwN/0H0KImnmfg4PHBQmjem5q+YMlgaXyamhawhXAJUAuPt4M+udyZu7+8vAy2nbrkpZduDC6CEi6T56KBSJa94KjrwbtjtedwdLg8uoDLW7L7Sf//J5TPGISKpOvWGLQXDwzdBWt9lIPDJJBJPN7ESgaXQD2LnAB/GGJVKgVi2Hd24MywOvht57h4dIjDIZLD6HMF/xCuBRQjlqzUcg0tC+HQV37wn/vQWW/hiKxIlkQSY9gi3d/XLg8riDESlIKxbDm0Ng9L3QsQec/B/YbEDSUUkBySQR/M3MNgCeBp5w90kxxyRSWBZ9F2YO2+W3sN+VsE7bpCOSAlPrqSF335cwM9lc4B4zm2hmV8QemUg+Wzo/TB4P0GWLUCTuoBuVBCQRGd1Q5u5z3P1W4AzCPQVX1fISEamKO0x+Du7oD69cDD9+EbZr2khJUCY3lG1lZteY2UTC5PUfEMpFiEhdLJ4DT5wMT50C7bvB4JJQKVQkYZmMEQwDngAOdPfvYo5HJD9VlMOwQbB4Nuw/BHY9C5omXfNRJKj1N9Hdd8tGICJ5aeFMaLdRKBJ3yM3QsRd03izpqER+ptpTQ2b2ZPTvRDObkPKYmDJzmYhUpaIcRt398yJxmw1UEpBGqaYewXnRv4dmIxCRvDF3Kjx/NswcDZvtD5sPSjoikRpV2yNw99nR4pnu/k3qAzgzO+GJ5JixD4S7g+dNg18MhZOeCjeJiTRimVw+un8V2w5q6EBE8sJ6m8KWh8JZo2G741QpVHJCtaeGzOx3hG/+m6SNCbQD3o87MJGcsGoZlFwPGOz/JxWJk5xU0xjBo8ArwPXAJSnbF7v7/FijEskFX78Pw8+B+V9C0WnhZjH1ACQH1ZQI3N2/NrOz0p8ws05KBlKwli+CN64JVwOt2wt+NRw22SfpqETWWm09gkOBjwgT0aR+1XFgkxjjEmm8Fs+B8Y/CbmfDvpdBizZJRyRSL9UmAnc/NPo3o2kpRfLaknkw+T/Q///ChPHnT9CMYZI3Mqk1tIeZtYmWTzazW8ysZ/yhiTQC7jDpmVAk7tVL4cdpYbuSgOSRTC4fvQtYambbARcBXwL/ijUqkcZg0Wx4/ER4+rRwL8Bv39GdwZKXMql6tdrd3cyOAG539/vN7PS4AxNJVEU5PHBQKBJ3wLWwy+9UJE7yVia/2YvN7FLg/wF7mVkToHm8YYkkpPTbUCK6SVM45G/hqqD1Nk06KpFYZXJq6DjCxPWnufscwlwEN8UalUi2VZTDB7fD7f1hTGWRuAFKAlIQMpmqcg7wCNDBzA4Flrv7w7FHJpIt30+B+/eH1y4P9wNseUjSEYlkVSZXDR0LjAaOAY4FPjSzo+MOTCQrxtwP9+wNC76Go+6HEx6HDt2SjkokqzIZI7gc2NndfwAwsy7AG8DTcQYmEqvKchBdtoCtj4RBN0CbzklHJZKITBJBk8okEJlHhpPeizQ6K5fC29eFweD9h0CvPcNDpIBlkgheNbMRwGPR+nHAy/GFJBKTr94LReIWfAU7/0ZF4kQimcxZ/Acz+yVQ+bVpqLs/G29YIg1o+UJ4/Sr46EFYtzec8oJKRYukqGk+gj7AzcCmwETg9+4+K1uBiTSYxd/DhCdh93Og+DJo0TrpiEQalZrO9Q8DXgSOIlQgva2ub25mg8xsqplNM7NLatjvKDNzMyuq6zFEqrTkR/jwnrDcZXM4f2K4Q1hJQGQNNZ0aaufu90bLU81sXF3e2MyaAncQprqcCYwxs+HuPiVtv3bAecCHdXl/kSq5s/7378Dtv4YVi2HTAaE+kK4IEqlWTT2Clma2g5ntaGY7Aq3S1mvTH5jm7tPdfSXwOHBEFfv9GbgRWF7n6EVSLZwJjx5H309vgU6bwBnvqUicSAZq6hHMBm5JWZ+Tsu7AfrW8dzdgRsr6TGCX1B2ihNLD3V8ysz9U90ZmNhgYDNC1a1dKSkpqOfSaSkuXUV5evlavzWVlZWUF0WarKKf/6DNpsXIBn/U4mbmb/BKmfB8eBaBQPudUanPDqWlimn0b/GgpouJ1twCn1ravuw8FhgIUFRV5cXFxnY9319SRlJaWsjavzWUlJSX53eYF30CH7uG+gI3vhnV7MXfCN/nd5irk/edcBbW54cR5Y9gsoEfKevdoW6V2QD+gxMy+BnYFhmvAWDJSvhrevzVMGDPmvrBt032hkybUE6mrOAusjwH6mFlvQgI4Hjix8kl3Xwj8bwTPzEoIl6iOjTEmyQdzJsHws+G7j2GLQ2Crw5OOSCSnxZYI3H21mZ0NjACaAsPcfbKZDQHGuvvwuI4teWz0vfDqJdCyIxz9AGz9C90dLFJPtSYCMzPgJGATdx8SzVe8gbuPru217v4yaeUo3P2qavYtzihiKUyV5SDW7wv9joIDr4c26yUdlUheyKRHcCdQQbhKaAiwGHgG2DnGuESClUvgrWvDYPAB10KvPcJDRBpMJoPFu7j7WUTX+bv7AqBFrFGJAEwvgTt3g1F3wuqVoVcgIg0ukx7BquguYYf/zUdQEWtUUtiWlcJrV8DH/4JOm8KvX4GNd086KpG8lUkiuBV4FljfzK4DjgauiDUqKWxL5sKk/8Ae50PxJdC8VdIRieS1TMpQP2JmHwEDAAOOdPdPY49MCkvZDzDpGdj1d9C5TygSp8FgkazI5KqhnsBS4IXUbe7+bZyBSYFwDyWiX704DAz3OQDW21RJQCSLMjk19BJhfMCAlkBvYCqwdYxxSSEonQEvXgDTXofu/eGI20MSEJGsyuTU0Dap61GhuDNji0gKQ/lqePCQMG/AQX8NU0c2aZp0VCIFqc53Frv7ODPbpfY9Raow/yvo2BOaNoPDbw1TR667cdJRiRS0TMYILkxZbQLsCHwXW0SSn8pXw8jb4O3rYf8hsOsZsElx0lGJCJn1CNqlLK8mjBk8E084kpdmTwhF4mZ/AlseClsfmXREIpKixkQQ3UjWzt1/n6V4JN98OBRGXAqtOsGxD0PfqiapE5EkVZsIzKxZVEFUhV2k7iqLxHXdGrY5Fg68Dlp3SjoqEalCTT2C0YTxgPFmNhx4ClhS+aS7/yfm2CQXrSiDt/4MTZqFP/4qEifS6GUyRtASmEeoPlp5P4EDSgTyc9PehBfOh4UzYJff/tQrEJFGraZEsH50xdAkfkoAlVQGUn6ybAGMuBzGPwLr9YmKxO2WdFQikqGaEkFToC0/TwCVlAjkJ0t+hCnPw54Xwj4XQ/OWSUckInVQUyKY7e5DshaJ5JbF38Okp2G3s34qEqfBYJGcVFMi0MldWZM7fPIYvHoprFoGmw8K9YGUBERyVk2JYEDWopDcsOAbePF8+PIt6LErHH6bisSJ5IFqE4G7z89mINLIla+Ghw6FpfPh4Juh6HRokslMpyLS2NW56JwUmHlfwrq9QpG4I+4Iyx17Jh2ViDQgfaWTqpWvgndvhjt3hdH3hm2991YSEMlD6hHImr4bH4rEzZkIfY+Efr9MOiIRiZESgfzcqLthxGXQpjMc92/Y6rCkIxKRmCkRSFBZDmLDbWG7E+DAa6HVuklHJSJZoERQ6FYshjf+BM3WCUXiNt49PESkYGiwuJB98QbcuRuMuS/0CFyVQ0QKkXoEhWjp/DAO8Mlj0HkLOP016NE/6ahEJCFKBIVo6Xz49EXY+4+w9+/DaSERKVixnhoys0FmNtXMppnZJVU8f6GZTTGzCWb2ppltHGc8BW3xHHj/1nD6p/NmcMFE2O9yJQERiS8RRPMd3wEcBPQFTjCzvmm7fQwUufu2wNPAX+OKp2C5w7h/we394e3rYP70sF1XBIlIJM4eQX9gmrtPd/eVwOPAz2Yud/e33X1ptDoK6B5jPIVnwddsO+HqcHPYBv3gjPdVJE5E1sfU79cAAA2ZSURBVBDnGEE3YEbK+kxglxr2Px14paonzGwwMBiga9eulJSU1DmY0tJllJeXr9Vrc5FVlNN/9Bm0W7mIz/ucwXcbHQiTZhI+hvxWVlZWMJ9zJbW5MMTV5kYxWGxmJwNFwD5VPe/uQ4GhAEVFRV5cXFznY9w1dSSlpaWszWtzSmWRuCZNofcwRk6dw26DjmHzpOPKopKSkvz/nNOozYUhrjbHeWpoFtAjZb17tO1nzGwgcDlwuLuviDGe/Fa+Ct65KSoSNzRs670XK1p2STYuEWn04uwRjAH6mFlvQgI4HjgxdQcz2wG4Bxjk7j/EGEt+mzUOhp8D30+CfkdBv6OTjkhEckhsicDdV5vZ2cAIoCkwzN0nm9kQYKy7DwduAtoCT5kZwLfufnhcMeWlUXeFm8PadoXjH4MtD046IhHJMbGOEbj7y8DLaduuSlkeGOfx81plkbiNdoAd/h/sPwRadUw6KhHJQY1isFjqYPkieONqaNYSBl0PPXcNDxGRtaSic7nk89fCYPBHD4arglQkTkQagHoEuWDJPHj1Epj4JHTZCo59GLoXJR2ViOQJJYJcsLwUPn8V9rkE9roImrVIOiIRySNKBI3Vou9gwpOwx3mhLMT5EzUYLCKxUCJobNxh3EPw2pXhJrGtDguJQElARGKiRNCYzJ8Ow8+Fr9+DXnvBYf9UkTgRiZ0SQWNRvhoeOgKWLYBD/wE7ngJNdFGXiMRPiSBpP34B6/aGps3gF3eF5Q7dko5KRAqIvnImZfVKKLkhmjz+3rCt155KAiKSdeoRJGHmR2GymB+mwDbHwDbHJh2RiBQwJYJsG3knvHY5tN0ATngCthiUdEQiUuCUCLKlskhct53CQPD+f4KWHZKOSkREiSB2yxfC61dBs1Zw0A3Qc5fwEBFpJDRYHKepr8Adu8C4h0NZCBWJE5FGSD2COCz5EV65GCY9DetvDcc/Ek4JiYg0QkoEcVi+EL54HYovgz0vUJE4EWnUlAgaysKZMOEJ2PPCUBbigokaDBaRnKBEUF8VFfDRA/D61eDl0PfIkAiUBEQkRygR1Me8L0ORuG/+C733CUXiOvVOOioRkTpRIlhb5avh4SPDeMDht8MOJ4f7BEREcowSQV3NnQqdNg1F4n55TygS137DpKMSEVlruo8gU6tXwNt/gbt2h9FDw7aNd1cSEJGcpx5BJmaMCUXi5n4G2x4P2x2fdEQiIg1GiaA2H9wWpo1s3w1Oehr67J90RCIiDUqJoDoVFWGGsO79oeg0GHgNtGyfdFQiIg1OiSDdstJQJrp5azj4JhWJE5G8p8HiVJ++GIrEjX8MWrRVkTgRKQjqEQCUzYWXfw9TnoMNtoETn4CNtk86KhGRrFAiAFixCKa/DftdCXucB02bJx2RiEjWFG4iKJ0BEx6HvX4fFYmbDOu0SzoqEZGsi3WMwMwGmdlUM5tmZpdU8fw6ZvZE9PyHZtYrzniAcDXQ6Hvhzl3hvVtg/vSwXUlARApUbInAzJoCdwAHAX2BE8ysb9pupwML3H0z4O/AjXHFA9C94jt48JAwHtB9ZzhzVOgNiIgUsDhPDfUHprn7dAAzexw4ApiSss8RwDXR8tPA7WZm7g1/uU4TL+e6lX+BH1bBEXfC9ieqSJyICPEmgm7AjJT1mUD6Bfn/28fdV5vZQmA94MfUncxsMDAYoGvXrpSUlNQ5mLa+gvvbnsm+/XqzcmEneOedOr9HLiorK1urn1cuU5sLg9rccHJisNjdhwJDAYqKiry4uLjO71FcDCUl67D7Wrw2l5WUlLA2P69cpjYXBrW54cQ5WDwL6JGy3j3aVuU+ZtYM6ADMizEmERFJE2ciGAP0MbPeZtYCOB4YnrbPcOCUaPlo4K04xgdERKR6sZ0ais75nw2MAJoCw9x9spkNAca6+3DgfuBfZjYNmE9IFiIikkWxjhG4+8vAy2nbrkpZXg4cE2cMIiJSMxWdExEpcEoEIiIFTolARKTAKRGIiBQ4y7WrNc1sLvDNWr68M2l3LRcAtbkwqM2FoT5t3tjdu1T1RM4lgvows7HuXpR0HNmkNhcGtbkwxNVmnRoSESlwSgQiIgWu0BLB0KQDSIDaXBjU5sIQS5sLaoxARETWVGg9AhERSaNEICJS4PIyEZjZIDObambTzOySKp5fx8yeiJ7/0Mx6ZT/KhpVBmy80sylmNsHM3jSzjZOIsyHV1uaU/Y4yMzeznL/UMJM2m9mx0Wc92cwezXaMDS2D3+2eZva2mX0c/X4fnEScDcXMhpnZD2Y2qZrnzcxujX4eE8xsx3of1N3z6kEoef0lsAnQAvgE6Ju2z5nA3dHy8cATScedhTbvC7SOln9XCG2O9msHvAuMAoqSjjsLn3Mf4GNg3Wh9/aTjzkKbhwK/i5b7Al8nHXc927w3sCMwqZrnDwZeAQzYFfiwvsfMxx5Bf2Cau09395XA48ARafscATwULT8NDDDL6Znsa22zu7/t7kuj1VGEGeNyWSafM8CfgRuB5dkMLiaZtPn/gDvcfQGAu/+Q5RgbWiZtdqB9tNwB+C6L8TU4d3+XMD9LdY4AHvZgFNDRzDaszzHzMRF0A2akrM+MtlW5j7uvBhYC62Ulunhk0uZUpxO+UeSyWtscdZl7uPtL2QwsRpl8zpsDm5vZ+2Y2yswGZS26eGTS5muAk81sJmH+k3OyE1pi6vr/vVY5MXm9NBwzOxkoAvZJOpY4mVkT4Bbg1IRDybZmhNNDxYRe37tmto27lyYaVbxOAB5097+Z2W6EWQ/7uXtF0oHlinzsEcwCeqSsd4+2VbmPmTUjdCfnZSW6eGTSZsxsIHA5cLi7r8hSbHGprc3tgH5AiZl9TTiXOjzHB4wz+ZxnAsPdfZW7fwV8TkgMuSqTNp8OPAng7iOBloTibPkqo//vdZGPiWAM0MfMeptZC8Jg8PC0fYYDp0TLRwNveTQKk6NqbbOZ7QDcQ0gCuX7eGGpps7svdPfO7t7L3XsRxkUOd/exyYTbIDL53X6O0BvAzDoTThVNz2aQDSyTNn8LDAAws60IiWBuVqPMruHAr6Krh3YFFrr77Pq8Yd6dGnL31WZ2NjCCcMXBMHefbGZDgLHuPhy4n9B9nEYYlDk+uYjrL8M23wS0BZ6KxsW/dffDEwu6njJsc17JsM0jgAPMbApQDvzB3XO2t5thmy8C7jWzCwgDx6fm8hc7M3uMkMw7R+MeVwPNAdz9bsI4yMHANGAp8Ot6HzOHf14iItIA8vHUkIiI1IESgYhIgVMiEBEpcEoEIiIFTolARKTAKRFIo2Rm5WY2PuXRq4Z9yxrgeA+a2VfRscZFd6jW9T3uM7O+0fJlac99UN8Yo/ep/LlMMrMXzKxjLftvn+vVOCV+unxUGiUzK3P3tg29bw3v8SDwors/bWYHADe7+7b1eL96x1Tb+5rZQ8Dn7n5dDfufSqi6enZDxyL5Qz0CyQlm1jaaR2GcmU00szUqjZrZhmb2bso35r2i7QeY2cjotU+ZWW1/oN8FNotee2H0XpPM7PxoWxsze8nMPom2HxdtLzGzIjO7AWgVxfFI9FxZ9O/jZnZISswPmtnRZtbUzG4yszFRjfnfZvBjGUlUbMzM+kdt/NjMPjCzLaI7cYcAx0WxHBfFPszMRkf7VlWxVQpN0rW39dCjqgfhrtjx0eNZwl3w7aPnOhPuqqzs0ZZF/14EXB4tNyXUG+pM+MPeJtp+MXBVFcd7EDg6Wj4G+BDYCZgItCHclT0Z2AE4Crg35bUdon9LiOY8qIwpZZ/KGH8BPBQttyBUkWwFDAauiLavA4wFelcRZ1lK+54CBkXr7YFm0fJA4Jlo+VTg9pTX/wU4OVruSKhF1Cbpz1uPZB95V2JC8sYyd9++csXMmgN/MbO9gQrCN+GuwJyU14wBhkX7Pufu481sH8JkJe9HpTVaEL5JV+UmM7uCUKfmdEL9mmfdfUkUw3+AvYBXgb+Z2Y2E00nv1aFdrwD/NLN1gEHAu+6+LDodta2ZHR3t14FQLO6rtNe3MrPxUfs/BV5P2f8hM+tDKLPQvJrjHwAcbma/j9ZbAj2j95ICpUQgueIkoAuwk7uvslBRtGXqDu7+bpQoDgEeNLNbgAXA6+5+QgbH+IO7P125YmYDqtrJ3T+3MNfBwcC1Zvamuw/JpBHuvtzMSoADgeMIE61AmG3qHHcfUctbLHP37c2sNaH+zlnArYQJeN52919EA+sl1bzegKPcfWom8Uph0BiB5IoOwA9REtgXWGPOZQvzMH/v7vcC9xGm+xsF7GFmlef825jZ5hke8z3gSDNrbWZtCKd13jOzjYCl7v5vQjG/quaMXRX1TKryBKFQWGXvAsIf9d9VvsbMNo+OWSUPs82dC1xkP5VSryxFfGrKrosJp8gqjQDOsah7ZKEqrRQ4JQLJFY8ARWY2EfgV8FkV+xQDn5jZx4Rv2/9097mEP4yPmdkEwmmhLTM5oLuPI4wdjCaMGdzn7h8D2wCjo1M0VwPXVvHyocCEysHiNK8RJgZ6w8P0ixAS1xRgnIVJy++hlh57FMsEwsQsfwWuj9qe+rq3gb6Vg8WEnkPzKLbJ0boUOF0+KiJS4NQjEBEpcEoEIiIFTolARKTAKRGIiBQ4JQIRkQKnRCAiUuCUCERECtz/By6Lqslpd2C1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}