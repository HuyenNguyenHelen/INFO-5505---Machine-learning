{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuyenNguyen_Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRPD6SpaJt8MxwZV3835gX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/INFO-5505---Machine-learning/blob/main/HuyenNguyen_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_yMppN_P_GC"
      },
      "source": [
        "# Assignment 4: Random Forest\r\n",
        "* Dataset: [Breast Cancer Wisconsin](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)\r\n",
        "* Goals: Given the Breast Cancer Features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass, train a model for predicting/diagnosing whether the observations are maglinant (M) or benign (B)\r\n",
        "*   Dependent variable/ Target variable: **diagnosis**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v4G3WymSZFw"
      },
      "source": [
        "# Importing essential libraries \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suY0adZlSPJc"
      },
      "source": [
        "## Loading the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "THqvxiSxTIiR",
        "outputId": "f99e664e-5f54-42b2-b159-cfb7c518ce26"
      },
      "source": [
        "# Loading the dataset\r\n",
        "data=pd.read_csv('/content/data-breastCancer.csv')\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6jwB19pjKH7"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA5PxtKNYmnP",
        "outputId": "d95d0507-6229-4b61-cc6d-5495c94da8ae"
      },
      "source": [
        "# Printing column names\r\n",
        "print('the number of columns: {}'.format(len(data.columns)))\r\n",
        "print('column names: \\n', [name for name in data.columns])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of columns: 33\n",
            "column names: \n",
            " ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mPgocuAY1dQ"
      },
      "source": [
        "There are 33 variables including the independent and dependent variables. However, two of them contain no useful information such as observation identity number. Therefore, we will delete these columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "3vkeJ2Xabk_k",
        "outputId": "de8a772f-0152-493c-c775-93bd9e5aeb7e"
      },
      "source": [
        "# Explore the dataset with some summary statistics\r\n",
        "data.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count   569.000000    569.000000  ...      569.000000               569.000000\n",
              "mean     14.127292     19.289649  ...        0.290076                 0.083946\n",
              "std       3.524049      4.301036  ...        0.061867                 0.018061\n",
              "min       6.981000      9.710000  ...        0.156500                 0.055040\n",
              "25%      11.700000     16.170000  ...        0.250400                 0.071460\n",
              "50%      13.370000     18.840000  ...        0.282200                 0.080040\n",
              "75%      15.780000     21.800000  ...        0.317900                 0.092080\n",
              "max      28.110000     39.280000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs-w788QdFae"
      },
      "source": [
        "The min, max, mean, and standard deviation from the above summary statistics of the dataset indicate that our data have different scales or ranges. However, fortunately, decision tree or random forest algorithms can handle well this issue because they made local optimums, unlike logistic regression or others. Therefore, we will not have to normalize our data, for maintain the model interpretability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgKSAJIOS7jq"
      },
      "source": [
        "### Exploring missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOE7WAcvajZp",
        "outputId": "2d8fea77-6634-4954-e8db-8d8db48ce01d"
      },
      "source": [
        "# Checking missing values in the dataset\r\n",
        "data.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULJ7Z-qMd8Gm"
      },
      "source": [
        "As we can see, there is no missing values, so we do not need to do data cleaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uok_QjEnTXgB"
      },
      "source": [
        "### Exploring the data distribution of the dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9J2RI7ojU-L",
        "outputId": "416e546e-677c-4cb0-d261-fe0dc4201741"
      },
      "source": [
        "# Explore data distribution on the dependent variable \r\n",
        "print( 'class distribution in the dependent variable: \\n', data['diagnosis'].value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class distribution in the dependent variable: \n",
            " B    357\n",
            "M    212\n",
            "Name: diagnosis, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "QCNEvWoPZsJX",
        "outputId": "20d9b90e-b302-4e31-fc74-8779e7f94528"
      },
      "source": [
        "sns.countplot(x='diagnosis', data=data)\r\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASDklEQVR4nO3df7BndX3f8efLBYWpJED2lm5216y1tAyauOgVSdI2BMeKpOmiQxyYSVwt0zUz2DFpJhNIO2psmWqDYaJJmFnKT2tU6o9CLLUhBHWcUXCh67KA1K1C2R1+XBEQQqSz67t/fD/349fL3eW7wLnfy97nY+bM95zP53PO932Zu/fF55zzPd9UFZIkAbxo2gVIkpYPQ0GS1BkKkqTOUJAkdYaCJKk7bNoFPBerV6+uDRs2TLsMSXpBufXWW79bVTOL9b2gQ2HDhg1s27Zt2mVI0gtKknv31+fpI0lSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVL3gv5Es3Qo+78f+Nlpl6Bl6GXvvX3Q4w82U0hyRJJbknwjyR1J/qC1X5nkO0m2t2Vja0+SjyTZlWRHktcMVZskaXFDzhSeAk6rqieSHA58Jcn/aH2/W1WfXjD+zcDxbXk9cEl7lSQtkcFmCjXyRNs8vC0H+kLoTcDVbb+vAUcnWTNUfZKkpxv0QnOSVUm2Aw8BN1TVza3rwnaK6OIkL2lta4H7xnbf3doWHnNLkm1Jts3NzQ1ZviStOIOGQlXtq6qNwDrg5CSvAi4ATgBeBxwL/N5BHnNrVc1W1ezMzKKPA5ckPUtLcktqVT0K3AScXlX3t1NETwFXACe3YXuA9WO7rWttkqQlMuTdRzNJjm7rRwJvBL45f50gSYAzgZ1tl+uAt7e7kE4BHquq+4eqT5L0dEPefbQGuCrJKkbhc01VfT7JXyeZAQJsB36zjb8eOAPYBTwJvHPA2iRJixgsFKpqB3DSIu2n7Wd8AecNVY8k6Zn5mAtJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkbrBQSHJEkluSfCPJHUn+oLW/PMnNSXYl+VSSF7f2l7TtXa1/w1C1SZIWN+RM4SngtKp6NbAROD3JKcCHgIur6h8AjwDntvHnAo+09ovbOEnSEhosFGrkibZ5eFsKOA34dGu/CjizrW9q27T+NyTJUPVJkp5u0GsKSVYl2Q48BNwA/B/g0ara24bsBta29bXAfQCt/zHgpxY55pYk25Jsm5ubG7J8SVpxBg2FqtpXVRuBdcDJwAnPwzG3VtVsVc3OzMw85xolST+yJHcfVdWjwE3AzwNHJzmsda0D9rT1PcB6gNb/k8DDS1GfJGlkyLuPZpIc3daPBN4I3MUoHM5qwzYD17b169o2rf+vq6qGqk+S9HSHPfOQZ20NcFWSVYzC55qq+nySO4FPJvkPwP8CLmvjLwM+lmQX8D3g7AFrkyQtYrBQqKodwEmLtH+b0fWFhe0/AH5tqHokSc/MTzRLkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYOFQpL1SW5KcmeSO5K8p7W/P8meJNvbcsbYPhck2ZXk7iRvGqo2SdLiDhvw2HuB36mq25IcBdya5IbWd3FVXTQ+OMmJwNnAK4GfBv4qyT+sqn0D1ihJGjPYTKGq7q+q29r648BdwNoD7LIJ+GRVPVVV3wF2AScPVZ8k6emW5JpCkg3AScDNrendSXYkuTzJMa1tLXDf2G67WSREkmxJsi3Jtrm5uQGrlqSVZ/BQSPJS4DPAb1XV94FLgFcAG4H7gQ8fzPGqamtVzVbV7MzMzPNeryStZIOGQpLDGQXCx6vqswBV9WBV7auqHwKX8qNTRHuA9WO7r2ttkqQlMuTdRwEuA+6qqj8aa18zNuwtwM62fh1wdpKXJHk5cDxwy1D1SZKebsi7j34R+A3g9iTbW9vvA+ck2QgUcA/wLoCquiPJNcCdjO5cOs87jyRpaQ0WClX1FSCLdF1/gH0uBC4cqiZJ0oH5iWZJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6ob85rUXhNf+7tXTLkHL0K1/+PZplyBNhTMFSVJnKEiSuolCIcmNk7RJkl7YDhgKSY5IciywOskxSY5tywZg7TPsuz7JTUnuTHJHkve09mOT3JDkW+31mNaeJB9JsivJjiSveX5+REnSpJ5ppvAu4FbghPY6v1wL/Mkz7LsX+J2qOhE4BTgvyYnA+cCNVXU8cGPbBngzcHxbtgCXHPRPI0l6Tg5491FV/THwx0n+dVV99GAOXFX3A/e39ceT3MVodrEJOLUNuwr4IvB7rf3qqirga0mOTrKmHUeStAQmuiW1qj6a5BeADeP7VNVE93O2000nATcDx439oX8AOK6trwXuG9ttd2v7sVBIsoXRTIKXvexlk7y9JGlCE4VCko8BrwC2A/tacwHPGApJXgp8Bvitqvp+kt5XVZWkDqbgqtoKbAWYnZ09qH0lSQc26YfXZoET26mdiSU5nFEgfLyqPtuaH5w/LZRkDfBQa98DrB/bfV1rkyQtkUk/p7AT+HsHc+CMpgSXAXdV1R+NdV0HbG7rmxldtJ5vf3u7C+kU4DGvJ0jS0pp0prAauDPJLcBT841V9S8OsM8vAr8B3J5ke2v7feCDwDVJzgXuBd7W+q4HzgB2AU8C75z0h5AkPT8mDYX3H+yBq+orQPbT/YZFxhdw3sG+jyTp+TPp3UdfGroQSdL0TXr30eOM7jYCeDFwOPA3VfUTQxUmSVp6k84UjppfbxeQNzH6lLIk6RBy0E9JrZH/BrxpgHokSVM06emjt45tvojR5xZ+MEhFkqSpmfTuo18dW98L3MPoFJIk6RAy6TUFPzMgSSvApF+ysy7J55I81JbPJFk3dHGSpKU16YXmKxg9huKn2/IXrU2SdAiZNBRmquqKqtrbliuBmQHrkiRNwaSh8HCSX0+yqi2/Djw8ZGGSpKU3aSj8S0YPrnuA0ZfenAW8Y6CaJElTMuktqR8ANlfVIwBJjgUuYhQWkqRDxKQzhZ+bDwSAqvoeo6/XlCQdQiYNhRclOWZ+o80UJp1lSJJeICb9w/5h4KtJ/mvb/jXgwmFKkiRNy6SfaL46yTbgtNb01qq6c7iyJEnTMPEpoBYCBoEkHcIO+tHZkqRDl6EgSeoGC4Ukl7eH5+0ca3t/kj1JtrfljLG+C5LsSnJ3Er/AR5KmYMiZwpXA6Yu0X1xVG9tyPUCSE4GzgVe2ff4syaoBa5MkLWKwUKiqLwPfm3D4JuCTVfVUVX0H2AWcPFRtkqTFTeOawruT7Ginl+Y/ELcWuG9szO7W9jRJtiTZlmTb3Nzc0LVK0oqy1KFwCfAKYCOjB+t9+GAPUFVbq2q2qmZnZnx6tyQ9n5Y0FKrqwaraV1U/BC7lR6eI9gDrx4aua22SpCW0pKGQZM3Y5luA+TuTrgPOTvKSJC8HjgduWcraJEkDPtQuySeAU4HVSXYD7wNOTbIRKOAe4F0AVXVHkmsYfWJ6L3BeVe0bqjZJ0uIGC4WqOmeR5ssOMP5CfMieJE2Vn2iWJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gYLhSSXJ3koyc6xtmOT3JDkW+31mNaeJB9JsivJjiSvGaouSdL+DTlTuBI4fUHb+cCNVXU8cGPbBngzcHxbtgCXDFiXJGk/BguFqvoy8L0FzZuAq9r6VcCZY+1X18jXgKOTrBmqNknS4pb6msJxVXV/W38AOK6trwXuGxu3u7U9TZItSbYl2TY3NzdcpZK0Ak3tQnNVFVDPYr+tVTVbVbMzMzMDVCZJK9dSh8KD86eF2utDrX0PsH5s3LrWJklaQksdCtcBm9v6ZuDasfa3t7uQTgEeGzvNJElaIocNdeAknwBOBVYn2Q28D/ggcE2Sc4F7gbe14dcDZwC7gCeBdw5VlyRp/wYLhao6Zz9db1hkbAHnDVWLJGkyfqJZktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTtsGm+a5B7gcWAfsLeqZpMcC3wK2ADcA7ytqh6ZRn2StFJNc6bwy1W1sapm2/b5wI1VdTxwY9uWJC2h5XT6aBNwVVu/CjhzirVI0oo0rVAo4C+T3JpkS2s7rqrub+sPAMcttmOSLUm2Jdk2Nze3FLVK0ooxlWsKwD+uqj1J/i5wQ5JvjndWVSWpxXasqq3AVoDZ2dlFx0iSnp2pzBSqak97fQj4HHAy8GCSNQDt9aFp1CZJK9mSh0KSv5PkqPl14J8BO4HrgM1t2Gbg2qWuTZJWummcPjoO+FyS+ff/86r6QpKvA9ckORe4F3jbFGqTpBVtyUOhqr4NvHqR9oeBNyx1PZKkH1lOt6RKkqbMUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSd2yC4Ukpye5O8muJOdPux5JWkmWVSgkWQX8KfBm4ETgnCQnTrcqSVo5llUoACcDu6rq21X1/4BPApumXJMkrRiHTbuABdYC941t7wZePz4gyRZgS9t8IsndS1TbSrAa+O60i1gOctHmaZegH+fv5rz35fk4ys/sr2O5hcIzqqqtwNZp13EoSrKtqmanXYe0kL+bS2e5nT7aA6wf217X2iRJS2C5hcLXgeOTvDzJi4GzgeumXJMkrRjL6vRRVe1N8m7gfwKrgMur6o4pl7WSeFpOy5W/m0skVTXtGiRJy8RyO30kSZoiQ0GS1BkKK1ySSvJfxrYPSzKX5PPTrEsCSLIvyfYk30hyW5JfmHZNh7pldaFZU/E3wKuSHFlVfwu8EW8D1vLxt1W1ESDJm4D/CPzSdEs6tDlTEMD1wK+09XOAT0yxFml/fgJ4ZNpFHOoMBcHoGVNnJzkC+Dng5inXI807sp0++ibwn4F/P+2CDnWePhJVtSPJBkazhOunW430Y8ZPH/08cHWSV5X30g/GmYLmXQdchKeOtExV1VcZPRhvZtq1HMqcKWje5cCjVXV7klOnXYy0UJITGD3p4OFp13IoMxQEQFXtBj4y7TqkBY5Msr2tB9hcVfumWdChzsdcSJI6rylIkjpDQZLUGQqSpM5QkCR1hoIkqfOWVKlJ8n7gCUbP2PlyVf3VFGv5wLRr0MpkKEgLVNV7rUErlaePtKIl+bdJ/neSrwD/qLVdmeSstv7eJF9PsjPJ1iRp7a9LsqM9rO0Pk+xs7e9I8tkkX0jyrST/aey9zklyezvWh1rbqvZ+O1vfby9SwweT3Nne76Il/Q+kFceZglasJK8FzgY2Mvq3cBtw64Jhf1JVH2jjPwb8c+AvgCuAf1VVX03ywQX7bAROAp4C7k7yUWAf8CHgtYwe//yXSc4E7gPWVtWr2nscvaDGnwLeApxQVbWwX3q+OVPQSvZPgM9V1ZNV9X1GDwVc6JeT3JzkduA04JXtD/NR7QFtAH++YJ8bq+qxqvoBcCfwM8DrgC9W1VxV7QU+DvxT4NvA30/y0SSnA99fcKzHgB8AlyV5K/Dkc/6ppQMwFKT9aN8v8WfAWVX1s8ClwBET7PrU2Po+DjAjr6pHgFcDXwR+k9F3Boz37wVOBj7NaJbyhcl/AungGQpayb4MnJnkyCRHAb+6oH8+AL6b5KXAWQBV9SjweJLXt/6zJ3ivW4BfSrI6ySpG313xpSSrgRdV1WeAfwe8Znyn9r4/WVXXA7/NKECkwXhNQStWVd2W5FPAN4CHgK8v6H80yaXATuCBBf3nApcm+SHwJUaneQ70XvcnOR+4idHTPv97VV2b5NXAFUnm/wftggW7HgVc22YtAf7Ns/hRpYn5lFTpWUjy0qp6oq2fD6ypqvdMuSzpOXOmID07v5LkAkb/hu4F3jHdcqTnhzMFSVLnhWZJUmcoSJI6Q0GS1BkKkqTOUJAkdf8f0rm+gk1Pwo0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DflcvXI8Uq_q"
      },
      "source": [
        "The dependent variable \"diagnosis\" contains binary values: M (malignant) and B (benight). However, the proportion of the two classes are imbalanced as shown from the above bar chart. We should keep this in mind later when we train and validate the model because with imbalanced of class values, our model may not have ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dGEXSmxdN5-"
      },
      "source": [
        "### Preprocessing\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW1oVTNisMQb"
      },
      "source": [
        "* Deleting the columns contain no information: \"id\" and \"Unnamed: 32\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyYMcu6vb1CS",
        "outputId": "345ee9be-d973-4fc0-ad80-00699e10b16b"
      },
      "source": [
        "# Deleting the columns contain no information\r\n",
        "del data['id']\r\n",
        "del data ['Unnamed: 32']\r\n",
        "\r\n",
        "# Printing the numer of columns after deleting id columns\r\n",
        "print('the number of columns: ', len(data.columns))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of columns:  31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeA6b9_RsF0k"
      },
      "source": [
        "* Convert discrete data into numeric. Here, only the dependent variable contain discrete values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "18EzjauFdlHA",
        "outputId": "fc65524f-72bf-4eba-818e-ea7e565a7605"
      },
      "source": [
        "data['diagnosis']=np.where(data['diagnosis']=='M', 1, 0)\r\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0          1        17.99  ...          0.4601                  0.11890\n",
              "1          1        20.57  ...          0.2750                  0.08902\n",
              "2          1        19.69  ...          0.3613                  0.08758\n",
              "3          1        11.42  ...          0.6638                  0.17300\n",
              "4          1        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQknD5EzdDs1"
      },
      "source": [
        "## Developing a Random Forest model\r\n",
        "Random forest algorithm overcomes limitations of Decision tree that is sensitive to any minor changes in the input data and tend to overfit because it maximize local optimum, so it performs poorly in unseen data. Random forest also solves problems of Bagging Decision tree that uses all features for spliting creation, creating complexity of the tree.\r\n",
        "Random forest not only  generates samples with bootstrapping method like bagging, but also take random collection of features for each subset.\r\n",
        "\r\n",
        "Here we will create a base model with Random Forest in sklearn. Then we will experiment a variety of parameters to select the best parameters for tuning the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxpCOnxQi9Av"
      },
      "source": [
        "### Spliting the data into training and testing sets\r\n",
        "Here we will split the data into two parts: training set (80%), and test set (20%). \r\n",
        "\r\n",
        "For the training set (80%), we will then use k-fold cross validation method for validate our models. By doing so, the training set will be splitted into k-folds (i.e., we decide to divide into 5 folds), 4 folds for training and 1 set for validating for each iteration. \r\n",
        "\r\n",
        "We will not use the test set (20%) until we have finished training, and model selection. We only use the test set for evaluating our selected model to ensure having the most reliable model evaluation result before deploying the model.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY81vgPTi5gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc1cdba-ac16-4522-b925-aa8469ddcaa5"
      },
      "source": [
        "# Spliting the data into training (80%) and testing (20%) sets\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X = data.drop('diagnosis', axis=1)\r\n",
        "y = data['diagnosis']\r\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y,train_size = 0.8)\r\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\r\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes of X_train, y_train:  (455, 30) (455,)\n",
            "Shapes of X_test, y_test:  (114, 30) (114,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK488A8ORL5z"
      },
      "source": [
        "### Based Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgo9TUt3dAyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9c2744-90d6-47ec-b23c-1ffd3d108f62"
      },
      "source": [
        "# Building a Random forest model\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "base_rf = RandomForestClassifier (random_state = 42)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGr1wDBTtOWe",
        "outputId": "de3f07fd-e20a-4688-adcf-9922126033f9"
      },
      "source": [
        "# Validate the model's performance using k-fold cross validation\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "cv = cross_validate (base_rf, X_train, y_train, cv = 5)\r\n",
        "print(\"Base model's accuracy score of 5-fold cross validation:\\n\", cv['test_score'])\r\n",
        "print(\"Base model's cross validation accuracy score: \\n\", cv['test_score'].mean())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model's accuracy score of 5-fold cross validation:\n",
            " [0.95604396 0.96703297 0.92307692 0.97802198 0.93406593]\n",
            "Base model's cross validation accuracy score: \n",
            " 0.9516483516483516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYqtnuqZSg4J"
      },
      "source": [
        "The base random forest model performed quite well, with an accuracy score of 0.967 on the training set. However, we still hope to improve the performance by tuning the hyperparameters. \r\n",
        "\r\n",
        "Let's see parameters used by the base model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wHy2MSwFF7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8975697e-e648-492b-85e8-34ed787b06c2"
      },
      "source": [
        "# Checking current parameters of the base model\r\n",
        "print(\"Base model's parameters:\\n\", base_rf.get_params())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model's parameters:\n",
            " {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPtJVhkde_wG"
      },
      "source": [
        "### Tunning parameters\r\n",
        "We can use GridSearch with Cross Validation for searching the best parameters. The algorithm ...\r\n",
        "\r\n",
        "Below are parameters that are most important for us to tune:\r\n",
        "\r\n",
        "\r\n",
        "*   'bootstrap':\r\n",
        "*   'max_depth':\r\n",
        "*   'max_features':\r\n",
        "*   'min_sample_leaf': \r\n",
        "*   'min_samples_split':\r\n",
        "*   'n_estimators':\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gWCzalNGLSy"
      },
      "source": [
        "#### Searching the best parameters for tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkxDrfIde3hB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b8753a-cfce-4bbf-d2e9-8352b8b6dc5e"
      },
      "source": [
        "# Tunning parameters\r\n",
        "\r\n",
        "# Using randomized search on hyperparameters\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "\r\n",
        "# Setting a grid of parameters to sample \r\n",
        "# Setting the number of trees in random forest classifiers\r\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10, endpoint = True)]\r\n",
        "# Setting the number of features for each tree\r\n",
        "max_features = ['auto', 'sqrt', 'log2']\r\n",
        "# Setting the number of depth levels for each tree\r\n",
        "max_depth = [int(x) for x in np.linspace(start = 3, stop = 36, num=33, endpoint = True)]\r\n",
        "# Setting the minimum number of samples required to split an internal node\r\n",
        "min_samples_split = [5, 10, 15]\r\n",
        "# Setting the minimum number of samples required to be at a leaf node \r\n",
        "min_samples_leaf = [3, 4,5]\r\n",
        "# Select bootstrap method for building trees \r\n",
        "bootstrap = ['True']\r\n",
        "\r\n",
        "# Create the random grid\r\n",
        "random_grid = {'n_estimators':n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\r\n",
        "print(random_grid)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36], 'min_samples_split': [5, 10, 15], 'min_samples_leaf': [3, 4, 5], 'bootstrap': ['True']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o57zWmwiCdP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7900e344-51fd-408b-dbba-64dd8555aae1"
      },
      "source": [
        "# Create a base randomforest model for tuning\r\n",
        "tune_base_rf = RandomForestClassifier(random_state=42)\r\n",
        "\r\n",
        "# Create a randomized search cross validation model for searching for the best hyperparameters for the base rf model over 100 parameters combination\r\n",
        "random_search_rf = RandomizedSearchCV (estimator=tune_base_rf, param_distributions  = random_grid, random_state=42, cv = 5, n_iter=100)\r\n",
        "\r\n",
        "# fit the randomized search CV model into the training set\r\n",
        "random_search_rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Print the best parameters\r\n",
        "random_search_rf.best_params_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': 'True',\n",
              " 'max_depth': 28,\n",
              " 'max_features': 'log2',\n",
              " 'min_samples_leaf': 3,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 300}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjO3BL-S1PZ"
      },
      "source": [
        "Using the cross validation randomized search method, we found the best parameters for our tuned random forest model. Hopefully, we could achieve a bit higher performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vjgI50oGC9i"
      },
      "source": [
        "### The tuned random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3HHL26EGfXT",
        "outputId": "5a4e758e-a739-4703-8b69-197af1e316f1"
      },
      "source": [
        "# Creating a tuned random forest model with the best parameters choosen by  the cv randomized search algorithm\r\n",
        "tuned_rf = RandomForestClassifier (n_estimators = 300, min_samples_split = 5, min_samples_leaf = 3, max_features = 'log2',  max_depth = 28, bootstrap = True, random_state=42)\r\n",
        "\r\n",
        "# Validating the model using k-fold cross validation (k=5)\r\n",
        "tuned_cv = cross_validate (tuned_rf, X_train, y_train, cv = 5)\r\n",
        "print(\"The tuned model's accuracy scores in 5-fold cross validation:\\n\", tuned_cv['test_score'])\r\n",
        "print(\"The final base tuned model's cv accuracy score: \\n\", tuned_cv['test_score'].mean())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tuned model's accuracy scores in 5-fold cross validation:\n",
            " [0.96703297 0.97802198 0.92307692 0.97802198 0.93406593]\n",
            "The final base tuned model's cv accuracy score: \n",
            " 0.956043956043956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUdiWgz-Za8C"
      },
      "source": [
        "Unfortunately, the tuned model performed a bit worse than the base model did. Therefore, we will select the base model as our final model.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igaqaxhxr4kj"
      },
      "source": [
        "### Evaluate the selected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S9xtqlJWFBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660935fb-8086-4984-fda7-01ec7fb06973"
      },
      "source": [
        "# Fit the selected model to the training set\r\n",
        "tuned_rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Applying the selected model to make prediction on the test set\r\n",
        "pred = tuned_rf.predict(X_test)\r\n",
        "\r\n",
        "# Observing the estimate probability of classess in the test set\r\n",
        "pred_prob = tuned_rf.predict_proba (X_test)\r\n",
        "print ('class_0', 'class_1')\r\n",
        "print(pred_prob[:10])\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_0 class_1\n",
            "[[9.55021164e-01 4.49788360e-02]\n",
            " [9.87833333e-01 1.21666667e-02]\n",
            " [2.73015873e-03 9.97269841e-01]\n",
            " [9.94269841e-01 5.73015873e-03]\n",
            " [9.72740741e-01 2.72592593e-02]\n",
            " [6.66666667e-04 9.99333333e-01]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.11428571e-02 9.88857143e-01]\n",
            " [9.84240741e-01 1.57592593e-02]\n",
            " [9.98222222e-01 1.77777778e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT8Pc2WW79ma"
      },
      "source": [
        "The result of the estimate probabilities show how classes were assigned. It is a nx2 array. The first column (dimension) is for class 0, and another for the class 1. In the first instance, it was assigned class 0 because it got a probability of 0.6 for this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psAItIyVj57U",
        "outputId": "20c38fbe-9238-4d05-ce74-d58d2d4ea406"
      },
      "source": [
        "# Evaluate the selected model on the test set with acurracy scores\r\n",
        "print('Accuracy of the selected model in the test set: {:.4f}'.format(tuned_rf.score(X_test, y_test)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the selected model in the test set: 0.9561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EescqEUnBCqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "050a0d58-0492-4518-b790-14707deffc5b"
      },
      "source": [
        "# Evaluate the selected model on the test set  with confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "conf_matrix = confusion_matrix(y_test, pred )\r\n",
        "# visualizing confusion matrix\r\n",
        "sns.heatmap(conf_matrix, annot = True)\r\n",
        "plt.xlabel ('predicted values')\r\n",
        "plt.ylabel ('actual values')\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'actual values')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpQfnpw917AJ"
      },
      "source": [
        "#### Evaluating the selected model with the ROC curve\r\n",
        "We were aware of the imbalanced proportions of the two classes in previous section. Therefore, accuracy score may not make sense. Note that the Malignant (class 1) acounts a lower portion in the dataset, so even if its accuracy is high, the cost for the low False Negative is quite high. Receiver Operating Characteristic (ROC) Curve is a good method that enables us to balance True Positive Rate (TPR) and False Positive Rate (FPR). \r\n",
        "\r\n",
        "*   TPR = TP/P = TP/(TP+FN)\r\n",
        "*   FPR = FP/N = FP/ (FP+TN)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvqaTtOrBpZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa1eceb-1e3f-4016-fde7-3542bd101d6f"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\r\n",
        "# Taking the probability of the class 1 (Malignant) on the test set\r\n",
        "pred_prob_c1 = pred_prob[:,1]\r\n",
        "\r\n",
        "# Getting True Positive Rate (tpr) and False Positive Rate (fpr)\r\n",
        "tpr, fpr, threshold = roc_curve (y_test,pred_prob_c1)\r\n",
        "\r\n",
        "# Computing Area Under the ROC Curve (roc_auc)\r\n",
        "roc_auc_score = roc_auc_score (y_test,pred_prob_c1)\r\n",
        "roc_auc_score"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9921367521367522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "uQeS22WmQp6U",
        "outputId": "15e7898d-b83d-4d7e-8761-9f2589790dff"
      },
      "source": [
        "# Visualizing the ROC Curve\r\n",
        "plt.plot(fpr, tpr)\r\n",
        "plt.plot([0,1], '--')\r\n",
        "plt.plot([0, 0], [1, 0] , c=\".8\")\r\n",
        "plt.plot([1, 1] , c=\".8\")\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}