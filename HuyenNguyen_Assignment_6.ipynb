{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuyenNguyen_Assignment 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yeN0bmgfNtw63Cuid8QTakawnkWmk80H",
      "authorship_tag": "ABX9TyOsipQQPtLOLp4NuFT7g/Rk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/INFO-5505---Machine-learning/blob/main/HuyenNguyen_Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuB2MoAtwaoZ"
      },
      "source": [
        "# Assignment 6: Image Classification with Convolutional Neural Network\n",
        "Dataset: [Intel Image Classification dataset](https://www.kaggle.com/puneet6060/intel-image-classification/data#)\n",
        "\n",
        "Goal: Classify images into 6 categories: building, forest, glacier, mountain, sea, and street."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vqsdqlg8_1y"
      },
      "source": [
        "# Import essential libraries\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob as gb \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwdbwfI8wmrO",
        "outputId": "2aad108a-e9c7-43c0-a61c-eb8ed09aaf06"
      },
      "source": [
        "# Checking the GPU installed\n",
        "# %tensorflow_version 2.x\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Po8_UkUda7s"
      },
      "source": [
        "# Loading data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvlvv5pqW3jk"
      },
      "source": [
        "# Install Kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Loading kaggle API key file\n",
        "!cd ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwpJKt8qZjl9",
        "outputId": "5b4c62e4-e3e8-41b9-94ee-e9f11194b8a6"
      },
      "source": [
        "# Downloading the dataset from Kaggle\n",
        "!kaggle datasets download -d puneet6060/intel-image-classification\n",
        "\n",
        "# Unzipping the dataset\n",
        "!unzip intel-image-classification.zip\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "intel-image-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  intel-image-classification.zip\n",
            "replace seg_pred/seg_pred/10004.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace seg_pred/seg_pred/10005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t-Cp_nBesMe"
      },
      "source": [
        "# Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2CePLfRodyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9263f947-bdf9-4dbf-9810-e332f608ac53"
      },
      "source": [
        "# Exploring sizes of the training, testing and prediction sets\n",
        "\n",
        "train_path = '/content/seg_train/seg_train'\n",
        "test_path = '/content/seg_test/seg_test'\n",
        "pred_path = '/content/seg_pred/seg_pred'\n",
        "\n",
        "def exploring_size (path):\n",
        "  size =0\n",
        "  try:\n",
        "    for name in os.listdir(path):\n",
        "      size += len(os.listdir(path + '/' + name))\n",
        "  except:\n",
        "    size += len(os.listdir(path))\n",
        "  return size\n",
        "\n",
        "print('The number of images in the training set: ', exploring_size(train_path))\n",
        "print('The number of images in the test set: ', exploring_size(test_path))\n",
        "print('The number of images in the prediction set: ', exploring_size(pred_path))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of images in the training set:  14034\n",
            "The number of images in the test set:  3000\n",
            "The number of images in the prediction set:  7301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdFX11Relz_-",
        "outputId": "c1151af7-cc6a-415f-fc59-d235fab74e11"
      },
      "source": [
        "# Exploring data's labels \n",
        "folder_names = os.listdir(train_path)\n",
        "print('All labels: ', folder_names)\n",
        "\n",
        "# Exploring data distribution in the training set\n",
        "print ('-'*30, '\\nData distributed in the training set:')\n",
        "for name in folder_names:\n",
        "  print (name, ': ', len(os.listdir(train_path + '/' + name)))\n",
        "\n",
        "# Exploring data distributed in the test set\n",
        "print ('-'*30, '\\nData distributed in the test set:')\n",
        "for name in folder_names:\n",
        "  print (name, ': ', len(os.listdir(test_path + '/' + name)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All labels:  ['street', 'mountain', 'buildings', 'sea', 'glacier', 'forest']\n",
            "------------------------------ \n",
            "Data distributed in the training set:\n",
            "street :  2382\n",
            "mountain :  2512\n",
            "buildings :  2191\n",
            "sea :  2274\n",
            "glacier :  2404\n",
            "forest :  2271\n",
            "------------------------------ \n",
            "Data distributed in the test set:\n",
            "street :  501\n",
            "mountain :  525\n",
            "buildings :  437\n",
            "sea :  510\n",
            "glacier :  553\n",
            "forest :  474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NE5SDbffYLg"
      },
      "source": [
        "# Adding a distribution graph"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4bl4WRSpu-n",
        "outputId": "c8aee0d0-0578-450f-c6ec-07607e7fb1ca"
      },
      "source": [
        "# Exploring the images' sizes\n",
        "def explore_image_size (path):\n",
        "  size = []\n",
        "  for name in os.listdir(path):\n",
        "    file_paths = gb.glob(pathname = path+ '/'+ name+'/*.jpg')\n",
        "    for p in file_paths:\n",
        "      size.append(plt.imread(p).shape)\n",
        "  return pd.DataFrame(size, columns = ['H', 'W', 'D']).value_counts()\n",
        "  \n",
        "print('Image sizes in the training set\\n',  explore_image_size (train_path))\n",
        "print('\\nImage sizes in the test set\\n',  explore_image_size (test_path))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image sizes in the training set\n",
            " H    W    D\n",
            "150  150  3    13986\n",
            "113  150  3        7\n",
            "135  150  3        3\n",
            "111  150  3        3\n",
            "144  150  3        2\n",
            "143  150  3        2\n",
            "142  150  3        2\n",
            "146  150  3        2\n",
            "136  150  3        2\n",
            "134  150  3        2\n",
            "108  150  3        2\n",
            "123  150  3        2\n",
            "97   150  3        1\n",
            "100  150  3        1\n",
            "81   150  3        1\n",
            "103  150  3        1\n",
            "105  150  3        1\n",
            "110  150  3        1\n",
            "102  150  3        1\n",
            "124  150  3        1\n",
            "115  150  3        1\n",
            "119  150  3        1\n",
            "120  150  3        1\n",
            "149  150  3        1\n",
            "131  150  3        1\n",
            "133  150  3        1\n",
            "140  150  3        1\n",
            "141  150  3        1\n",
            "145  150  3        1\n",
            "147  150  3        1\n",
            "76   150  3        1\n",
            "dtype: int64\n",
            "\n",
            "Image sizes in the test set\n",
            " H    W    D\n",
            "150  150  3    2993\n",
            "149  150  3       1\n",
            "141  150  3       1\n",
            "131  150  3       1\n",
            "110  150  3       1\n",
            "81   150  3       1\n",
            "76   150  3       1\n",
            "72   150  3       1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juEoD1vuAKLo"
      },
      "source": [
        "We can see  that most images have the size 150x150x3. It's reasonable to resize all images to this size. However, we want to reduce all images into a size of 64x64x3 to reduce training time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phFlbK4G9dwX"
      },
      "source": [
        "# Data Preprocessing\n",
        "For data processing, we would like to rescale our images so that every image's pixel value ranges between 0 and 1.\n",
        "Futher, we should apply data augmentation since our dataset is not large. Data Augmentation is a wise way to inc....for the training set that can help the model avoid overfitting. Some data augmentations we could use are rotating images with some random angles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCrBD5Kef39q",
        "outputId": "acc0b1e4-159e-41c8-e13e-ffcbee24b8cf"
      },
      "source": [
        "# Encoding data labels\n",
        "encoded_labels = dict()\n",
        "for v, k in enumerate(folder_names):\n",
        "  encoded_labels[k]=v  \n",
        "print('labels encoded:', encoded_labels)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels encoded: {'street': 0, 'mountain': 1, 'buildings': 2, 'sea': 3, 'glacier': 4, 'forest': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkFZ1CWNNm1f",
        "outputId": "ae0e024b-3e05-475e-c28d-dfa96b81fca6"
      },
      "source": [
        "\n",
        "# Resizing images\n",
        "def resize_image_xy (path):\n",
        "  X, y = [],[]\n",
        "  for name in os.listdir(path):\n",
        "    file_paths = gb.glob(pathname = path+ '/'+ name+'/*.jpg')\n",
        "    for p in file_paths:\n",
        "      image = plt.imread(p)\n",
        "      resized_image = cv2.resize(image,(64,64) )\n",
        "      X.append(resized_image)\n",
        "      y.append(encoded_labels[name])\n",
        "  return X, y\n",
        "\n",
        "def resize_image_x (path):\n",
        "  X = []\n",
        "  for name in os.listdir(path):\n",
        "    path_file = path+'/'+ name\n",
        "    image = plt.imread(path_file)\n",
        "    resized_image = cv2.resize(image,(64,64) )\n",
        "    X.append(resized_image)\n",
        "  return X\n",
        "\n",
        "\n",
        "# For images in the training set\n",
        "X_train, y_train = resize_image_xy (train_path)\n",
        "print('The number of images in the training set:', len(X_train), len(y_train))\n",
        "\n",
        "# For images in the test set\n",
        "X_test, y_test = resize_image_xy (test_path)\n",
        "print('The number of images in the testing set:', len(X_test), len(y_test))\n",
        "\n",
        "#For images in the predicting set\n",
        "X_pred = resize_image_x (pred_path)\n",
        "print('The number of images in the predicting set:', len(X_pred))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of images in the training set: 14034 14034\n",
            "The number of images in the testing set: 3000 3000\n",
            "The number of images in the predicting set: 7301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqk6aKWffeer",
        "outputId": "6fde3612-697c-43eb-ba92-4f595e2ba6f0"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = sklearn.utils.shuffle(np.array(X_train), np.array(y_train), random_state = 42)\n",
        "X_test, y_test = sklearn.utils.shuffle(np.array(X_test), np.array(y_test))\n",
        "X_pred = np.array(X_pred)\n",
        "print('The shape of X_train:', X_train.shape)\n",
        "print('The shape of y_train:', y_train.shape)\n",
        "print('The shape of X_test:', X_test.shape)\n",
        "print('The shape of y_test:', y_test.shape)\n",
        "print('The shape of X_pred:', X_pred.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X_train: (14034, 64, 64, 3)\n",
            "The shape of y_train: (14034,)\n",
            "The shape of X_test: (3000, 64, 64, 3)\n",
            "The shape of y_test: (3000,)\n",
            "The shape of X_pred: (7301, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "NDnXUgn7QFQ7",
        "outputId": "4159aa0b-ed1d-43fa-89c6-523e1fe389b9"
      },
      "source": [
        "'''\n",
        "# Reformat datatypes of the input and target data\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "X_pred = np.array(X_pred)\n",
        "print('The shape of X_train:', X_train.shape)\n",
        "print('The shape of y_train:', y_train.shape)\n",
        "print('The shape of X_test:', X_test.shape)\n",
        "print('The shape of y_test:', y_test.shape)\n",
        "print('The shape of X_pred:', X_pred.shape)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Reformat datatypes of the input and target data\\nX_train = np.array(X_train)\\ny_train = np.array(y_train)\\nX_test = np.array(X_test)\\ny_test = np.array(y_test)\\nX_pred = np.array(X_pred)\\nprint('The shape of X_train:', X_train.shape)\\nprint('The shape of y_train:', y_train.shape)\\nprint('The shape of X_test:', X_test.shape)\\nprint('The shape of y_test:', y_test.shape)\\nprint('The shape of X_pred:', X_pred.shape)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wwVXlRw2HoW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "8e783d51-1856-4f63-97ce-886bffee64f2"
      },
      "source": [
        "'''\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Preprocessing the training set\n",
        "# Creating a data augmentation model\n",
        "train_generator = ImageDataGenerator(rescale = 1./255,    \n",
        "                                      shear_range = 0.2,\n",
        "                                      rotation_range=20,\n",
        "                                      zoom_range = 0.2,\n",
        "                                      horizontal_flip = True)\n",
        "train_generated = train_generator.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "#train_generated = train_generator.flow_from_directory(train_path,\n",
        "                                                      target_size = (64, 64),\n",
        "                                                      batch_size = 32,\n",
        "                                                      class_mode = 'categorical')\n",
        "\n",
        "# Preprocessing the testing set\n",
        "test_generator = ImageDataGenerator(rescale = 1./255)\n",
        "test_generated = test_generator.flow(X_test, y_test, batch_size=32)\n",
        "#test_generated = test_generator.flow_from_directory(test_path, \n",
        "                                                    target_size = (64,64),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical')\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom keras.preprocessing.image import ImageDataGenerator\\n# Preprocessing the training set\\n# Creating a data augmentation model\\ntrain_generator = ImageDataGenerator(rescale = 1./255,    \\n                                      shear_range = 0.2,\\n                                      rotation_range=20,\\n                                      zoom_range = 0.2,\\n                                      horizontal_flip = True)\\ntrain_generated = train_generator.flow(X_train, y_train, batch_size=32)\\n\\n#train_generated = train_generator.flow_from_directory(train_path,\\n                                                      target_size = (64, 64),\\n                                                      batch_size = 32,\\n                                                      class_mode = 'categorical')\\n\\n# Preprocessing the testing set\\ntest_generator = ImageDataGenerator(rescale = 1./255)\\ntest_generated = test_generator.flow(X_test, y_test, batch_size=32)\\n#test_generated = test_generator.flow_from_directory(test_path, \\n                                                    target_size = (64,64),\\n                                                    batch_size = 32,\\n                                                    class_mode = 'categorical')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZBLfxbaskLA"
      },
      "source": [
        "# Building a base CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jK_ID_zs5L6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "\n",
        "# Defining a CNN model\n",
        "def define_cnn():\n",
        "  # Creating the model\n",
        "  cnn = Sequential()\n",
        "\n",
        "  # Convolution 1\n",
        "  cnn.add(Conv2D(32, (3,3), activation='relu', input_shape = (64,64,3)))\n",
        "  # Maxpooling 1\n",
        "  cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  # Convolution 2\n",
        "  cnn.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "  # Maxpooling 2\n",
        "  cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  # Convolution 3\n",
        "  cnn.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "  #  Maxpooling 3\n",
        "  cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  # Flatten\n",
        "  cnn.add(Flatten())\n",
        "  \n",
        "  # Fully-connected NN layer\n",
        "  cnn.add(Dense(32, activation = 'relu'))\n",
        "  cnn.add(Dense(16, activation = 'relu'))\n",
        "  cnn.add(Dense(6, activation = 'softmax'))\n",
        "  return cnn\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "2ivilJMlLtpe",
        "outputId": "b3e8b2c5-de9f-4f0f-a2c3-d3d019da08bd"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Defining 10-fold cross validation for validating the model in the training set\n",
        "kfold = KFold(n_splits = 10, shuffle = True) #random_state = 42\n",
        "fold_accuracy = []\n",
        "fold_loss = []\n",
        "fold = 1\n",
        "\n",
        "for train, test in kfold.split(np.zeros(len(y_train)),y_train):\n",
        "  # Preprocessing \n",
        "  train_generator = ImageDataGenerator(rescale = 1./255,    \n",
        "                                      shear_range = 0.2,\n",
        "                                      rotation_range=20,\n",
        "                                      zoom_range = 0.2,\n",
        "                                      horizontal_flip = True)\n",
        "  train_generated = train_generator.flow(X_train[train], y_train[train], batch_size=32)\n",
        "\n",
        "  test_generator = ImageDataGenerator(rescale = 1./255)\n",
        "  test_generated = test_generator.flow(X_train[test], y_train[test], batch_size=32)\n",
        "  \n",
        "  # Create the cnn model\n",
        "  cnn2 = define_cnn()\n",
        "  \n",
        "  # Compile the model\n",
        "  cnn2.compile(optimizer = 'adam', \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics = ['accuracy'])\n",
        "  print ('-'*35, '\\nTraining on fold {}'.format(fold))\n",
        "\n",
        "  # Fit the model into the training set\n",
        "  history = cnn2.fit(train_generated,  \n",
        "                    epochs = 5,\n",
        "                    validation_data=(test_generated) )\n",
        "  \n",
        "  # Create validation metrics\n",
        "  scores = cnn2.evaluate(test_generated, verbose=1)\n",
        "\n",
        "  print(f\"Score of fold: {fold}: {cnn2.metrics_names[0]} is {scores[0]}, {cnn2.metrics_names[1]} is {scores[1]}\")\n",
        "  fold_loss.append(scores[0])\n",
        "  fold_accuracy.append(scores[1])\n",
        "  fold += 1\n",
        "\n",
        "# Printing the average scores of 10 folders to get the generalized scores of the model\n",
        "print('-'*35)\n",
        "print('The generalized scores of the model:')\n",
        "print('Accuracy: ', np.mean(fold_accuracy))\n",
        "print('Loss: ', np.mean(fold_loss))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------- \n",
            "Training on fold 1\n",
            "Epoch 1/5\n",
            "395/395 [==============================] - 34s 37ms/step - loss: 1.3798 - accuracy: 0.4478 - val_loss: 0.9597 - val_accuracy: 0.6382\n",
            "Epoch 2/5\n",
            "395/395 [==============================] - 14s 35ms/step - loss: 0.9190 - accuracy: 0.6492 - val_loss: 0.9093 - val_accuracy: 0.6603\n",
            "Epoch 3/5\n",
            "252/395 [==================>...........] - ETA: 5s - loss: 0.8256 - accuracy: 0.6976"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2454256dfdfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   history = cnn2.fit(train_generated,  \n\u001b[1;32m     31\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     validation_data=(test_generated) )\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m# Create validation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F0LhrKqN2Rk"
      },
      "source": [
        "'''\n",
        "# Defining 10-fold cross validation for validating the model in the training set\n",
        "kfold = KFold(n_splits = 10, shuffle = True) #random_state = 42\n",
        "fold_accuracy, fold_loss = [],[]\n",
        "fold = 1\n",
        "for train, test in kfold.split(X_train, y_train):\n",
        "  # Create the cnn model\n",
        "  cnn = define_cnn()\n",
        "  \n",
        "  # Compile the model\n",
        "  cnn.compile(optimizer = 'adam', \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics = ['accuracy'])\n",
        "  print ('-'*35, '\\nTraining on fold {}'.format(fold))\n",
        "\n",
        "  # Fit the model into the training set\n",
        "  history = cnn.fit(X_train[train], \n",
        "                    y_train[train], \n",
        "                    epochs = 10,\n",
        "                    validation_data=(X_train[test], y_train[test]) )\n",
        "  \n",
        "  # Create validation metrics\n",
        "  scores = cnn.evaluate(X_train[test], y_train[test], verbose=1)\n",
        "  print(f\"Score of fold: {fold}: {cnn.metrics_names[0]} is {scores[0]}, {cnn.metrics_names[1]} is {scores[1]}\")\n",
        "  fold_loss.append(scores[0])\n",
        "  fold_accuracy.append(scores[1])\n",
        "  fold += 1\n",
        "\n",
        "# Printing the average scores of 10 folders to get the generalized scores of the model\n",
        "print('-'*35)\n",
        "print('The generalized scores of the model:')\n",
        "print('Accuracy: ', np.mean(fold_accuracy))\n",
        "print('Loss: ', np.mean(fold_loss))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg5inY34QXfY"
      },
      "source": [
        "# Fitting the model in the whole training set\n",
        "\n",
        "train_generated = train_generator.flow(X_train, y_train, batch_size=32)\n",
        "test_generated = test_generator.flow(X_test, y_test, batch_size=32)\n",
        "\n",
        "cnn2.fit(train_generated, epochs = 5,  verbose = 1)\n",
        "model_loss, model_accuracy = cnn2.evaluate(test_generated)\n",
        "print(cnn2.summary())\n",
        "print(model_loss, model_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O5xs8diea0Z"
      },
      "source": [
        "'''\n",
        "# Fitting the model in the whole training set\n",
        "cnn.fit(X_train, y_train, epochs = 10,  verbose = 1)\n",
        "model_loss, model_accuracy = cnn.evaluate(X_test, y_test)\n",
        "print(cnn.summary())\n",
        "print(model_loss, model_accuracy)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyIF4sruprgL"
      },
      "source": [
        "# Applying the model to predict on the test set\n",
        "y_test_pred = np.argmax(cnn2.predict(test_generated), axis=-1) \n",
        "y_test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDw3t77copok"
      },
      "source": [
        "# Evaluating the model with confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "## Visualizing the confusion matrix\n",
        "plt.figure(figsize=(10,10))\n",
        "labels = [label for label in encoded_labels.keys() ]\n",
        "sns.heatmap(conf_matrix, annot = True, fmt=\".0f\" )\n",
        "plt.xticks(np.arange(6), labels, rotation = 60, ha='right' )\n",
        "plt.yticks(np.arange(6), labels)\n",
        "plt.xlabel ('predicted values')\n",
        "plt.ylabel ('actual values')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHD7l7sWan6J"
      },
      "source": [
        "# Plotting the performance of the model over training\n",
        "plt.plot(history.history['accuracy'], label = 'train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy in training and validation over epoches')\n",
        "plt.ylim([0.4, 1])\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAMC2ygLiRPb"
      },
      "source": [
        "# Applied the model to predict the unseen data\n",
        "pred_generator = ImageDataGenerator(rescale = 1./255)\n",
        "pred_generated = pred_generator.flow(X_pred, batch_size=32)\n",
        "y_pred = cnn2.predict(pred_generated, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGA2rnJRP-rt"
      },
      "source": [
        "# Defining the function for predicting the unseen data\n",
        "def pred_image(path):\n",
        "    image=Image.open(path)\n",
        "    image=image.resize((64,64))\n",
        "    x=np.array(image)\n",
        "    x=np.expand_dims(x,axis=0)\n",
        "    classs=model.predict_classes(x)\n",
        "    l=os.listdir('../input/intel-image-classification/seg_train/seg_train')\n",
        "    l.sort()\n",
        "    return l[classs[0]]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}